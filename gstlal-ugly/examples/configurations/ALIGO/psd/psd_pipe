#!/usr/bin/python
"""
This program makes a dag to generate svd banks
"""

__author__ = 'Chad Hanna <channa@caltech.edu>'

##############################################################################
# import standard modules and append the lalapps prefix to the python path
import sys, os, copy, math
import subprocess, socket, tempfile

##############################################################################
# import the modules we need to build the pipeline
from glue import iterutils
from glue import pipeline
from glue import lal
from glue.ligolw import lsctables
from ligo import segments
import glue.ligolw.utils as utils
import glue.ligolw.utils.segments as ligolw_segments
from optparse import OptionParser

def which(prog):
	which = subprocess.Popen(['which',prog], stdout=subprocess.PIPE)
	out = which.stdout.read().strip()
	if not out: 
		print >>sys.stderr, "ERROR: could not find %s in your path, have you built the proper software and source the proper env. scripts?" % (prog,prog)
		raise ValueError 
	return out

def log_path():
	host = socket.getfqdn()
	#FIXME add more hosts as you need them
	if 'caltech.edu' in host: return '/usr1/' + os.environ['USER']
	if 'phys.uwm.edu' in host: return '/localscratch/' + os.environ['USER']
	if 'aei.uni-hannover.de' in host: return '/local/user/' + os.environ['USER']
	if 'phy.syr.edu' in host: return '/usr1/' + os.environ['USER']


class bank_DAG(pipeline.CondorDAG):

	def __init__(self, name, logpath = log_path()):
		self.basename = name
		tempfile.tempdir = logpath
		tempfile.template = self.basename + '.dag.log.'
		logfile = tempfile.mktemp()
		fh = open( logfile, "w" )
		fh.close()
		pipeline.CondorDAG.__init__(self,logfile)
		self.set_dag_file(self.basename)
		self.jobsDict = {}
		self.node_id = 0
		self.output_cache = []

	def add_node(self, node):
		node.set_retry(3)
		self.node_id += 1
		node.add_macro("macroid", self.node_id)
		pipeline.CondorDAG.add_node(self, node)

	def write_cache(self):
		out = self.basename + ".cache"
		f = open(out,"w")
		for c in self.output_cache:
			f.write(str(c)+"\n")
		f.close()

class gstlal_reference_psd_job(pipeline.CondorDAGJob):
	"""
	A gstlal_reference_psd job
	"""
	def __init__(self, executable=which('gstlal_reference_psd'), tag_base='gstlal_reference_psd'):
		"""
		"""
		self.__prog__ = 'gstlal_reference_psd'
		self.__executable = executable
		self.__universe = 'vanilla'
		pipeline.CondorDAGJob.__init__(self,self.__universe,self.__executable)
		self.add_condor_cmd('getenv','True')
		self.add_condor_cmd('requirements', 'Memory > 1999') #FIXME is this enough?
		self.tag_base = tag_base
		self.add_condor_cmd('environment',"KMP_LIBRARY=serial;MKL_SERIAL=yes")
		self.set_sub_file(tag_base+'.sub')
		self.set_stdout_file('logs/'+tag_base+'-$(macroid)-$(process).out')
		self.set_stderr_file('logs/'+tag_base+'-$(macroid)-$(process).err')


class gstlal_reference_psd_node(pipeline.CondorDAGNode):
	"""
	A gstlal_reference_psd node
	"""
	def __init__(self, job, dag, frame_cache, gps_start_time, gps_end_time, instrument, channel, injections=None, p_node=[]):

		pipeline.CondorDAGNode.__init__(self,job)
		self.add_var_opt("frame-cache", frame_cache)
		self.add_var_opt("gps-start-time",gps_start_time)
		self.add_var_opt("gps-end-time",gps_end_time)
		self.add_var_opt("instrument", instrument)
		self.add_var_opt("channel", channel)
		if injections: self.add_var_opt("injections", injections)
		path = os.getcwd()
		output_name = '%s/%s-%d-%d-reference_psd.xml.gz' % (path, instrument, gps_start_time, gps_end_time)
		self.add_var_opt("write-psd",output_name)
		dag.output_cache.append(lal.CacheEntry(instrument, "-", segments.segment(gps_start_time, gps_end_time), "file://localhost/%s" % (output_name,)))
		for p in p_node:
			self.add_parent(p)
		dag.add_node(self)


def breakupsegs(seglists, min_segment_length):
	for instrument, seglist in seglists.iteritems():
		newseglist = segments.segmentlist()
		for seg in seglist:
			if abs(seg) > min_segment_length:
				newseglist.append(segments.segment(seg))
		seglists[instrument] = newseglist


def parse_command_line():
	parser = OptionParser(description = __doc__)
	parser.add_option("--segment-file", metavar = "filename", help = "Set the name of the xml file to get segments (required).")
	parser.add_option("--min-segment-length", metavar = "seconds", help = "Set the minimum segment length (required)", type="float")
	parser.add_option("--injections", metavar = "filename", help = "Set the name of the xml file to get a cache of svd banks (optional)")
	parser.add_option("--frame-cache", metavar = "filenames", help = "Set the frame cache files in format H1=H1.cache,H2=H2.cache, etc..")
	#FIXME get this from the cache?
	parser.add_option("--channel", metavar = "name", help = "Set the channel name (default=LSC-STRAIN)", default="LSC-STRAIN")
	
	options, filenames = parser.parse_args()

	fail = ""
	for option in ("segment_file","min_segment_length", "frame_cache"):
		if getattr(options, option) is None:
			fail += "must provide option %s\n" % (option)
	if fail: raise ValueError, fail

	framecache = {}
	for c in options.frame_cache.split(','):
		ifo = c.split("=")[0]
		cache = c.replace(ifo+"=","")
		framecache[ifo] = cache
	
	return options, filenames, framecache#, process_params


options, filenames, frame_cache = parse_command_line()

try: os.mkdir("logs")
except: pass
dag = bank_DAG("psd_pipe")

seglists = ligolw_segments.segmenttable_get_by_name(utils.load_filename(options.segment_file), "datasegments")
breakupsegs(seglists, options.min_segment_length)

psdJob = gstlal_reference_psd_job()

for instrument, seglist in seglists.iteritems():
	for seg in seglist:
		#FIXME if there are sements without frame caches this will barf
		gstlal_reference_psd_node(psdJob, dag, frame_cache[instrument], int(seg[0]), int(seg[1]), instrument, options.channel, injections=options.injections, p_node=[])
		
dag.write_sub_files()
dag.write_dag()
dag.write_script()
dag.write_cache()



