#!/usr/bin/env python

# Copyright (C) 2017 Sydney J. Chamberlin, Patrick Godwin, Chad Hanna, Duncan Meacher
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.



####################
# 
#     preamble
#
####################   


from optparse import OptionParser
from collections import deque
import os
import sys
import StringIO

import gi
gi.require_version('Gst', '1.0')
from gi.repository import GObject, Gst
GObject.threads_init()
Gst.init(None)
import lal

import numpy
from gstlal import datasource
from gstlal import idq_multirate_datasource
from gstlal import multichannel_datasource
from gstlal import sngltriggertable
from gstlal import pipeparts
from gstlal import simplehandler
from glue.ligolw import utils as ligolw_utils

####################
# 
#    functions
#
####################   


def parse_command_line():

	parser = OptionParser(description = __doc__)

	#
	# First append the datasource common options
	#

	multichannel_datasource.append_options(parser)
	parser.add_option("--out-path", metavar = "path", default = ".", help = "Write to this path. Default = .")
	parser.add_option("--out-file", metavar = "filename", default = "output_triggers.trg", help = "Set the filename in which to save the output.")
	parser.add_option("--downsample-rate", metavar = "Hz", type = "int", default = 16, help = "Downsample input to this minimum sample rate. Default = 16 Hz.")
	parser.add_option("-v", "--verbose", action = "store_true", help = "Be verbose.")

	#
	# parse the arguments and sanity check
	#

	options, filenames = parser.parse_args()
	if options.downsample_rate % 2:
		raise ValueError("Minimum rate is not a power of 2")

	return options, filenames

####################
# 
#      classes
#
####################   


class MultiChannelHandler(simplehandler.Handler):
	def __init__(self, *args, **kwargs):
		self.out_file = kwargs.pop("out_file")
		self.out_path = kwargs.pop("out_path")
		super(MultiChannelHandler, self).__init__(*args, **kwargs)
		self.timedeq = deque(maxlen = 10000)

	def do_on_message(self, bus, message):
		return False

	def bufhandler(self, elem, sink_dict):
		buf = elem.emit("pull-sample").get_buffer()
		buftime = int(buf.pts / 1e9)
		channel = sink_dict[elem]
		fdata = ""	
		for i in range(buf.n_memory()):
			memory = buf.peek_memory(i)
			result, mapinfo = memory.map(Gst.MapFlags.READ)
			assert result
			# NOTE NOTE NOTE NOTE
			# It is critical that the correct class'
			# .from_buffer() method be used here.  This
			# code is interpreting the buffer's
			# contents as an array of C structures and
			# building instances of python wrappers of
			# those structures but if the python
			# wrappers are for the wrong structure
			# declaration then terrible terrible things
			# will happen
			if mapinfo.data:
				for row in sngltriggertable.GSTLALSnglTrigger.from_buffer(mapinfo.data):
					fdata += "%s\t%s\t%s\t%s\t%s\t%s\n" % (channel, row.end_time + row.end_time_ns*1e-9, row.phase, row.snr, row.chisq, row.sigmasq)
				self.timedeq.append(buftime)
			memory.unmap(mapinfo)

		# Save a "latest"
		self.to_trigger_file(os.path.join(self.out_path, self.out_file), fdata)
		
		del buf
		return Gst.FlowReturn.OK

	def to_trigger_file(self, path, data):
		with open(path, 'a') as f:
 			f.write(data)


class LinkedAppSync(pipeparts.AppSync):
	def __init__(self, appsink_new_buffer, sink_dict = {}):
		super(LinkedAppSync, self).__init__(appsink_new_buffer, sink_dict.keys())
		self.sink_dict = sink_dict	
	
	def attach(self, appsink):
		"""
		connect this AppSync's signal handlers to the given appsink
		element.  the element's max-buffers property will be set to
		1 (required for AppSync to work).
		"""
		if appsink in self.appsinks:
			raise ValueError("duplicate appsinks %s" % repr(appsink))
		appsink.set_property("max-buffers", 1)
		handler_id = appsink.connect("new-preroll", self.new_preroll_handler)
		assert handler_id > 0
		handler_id = appsink.connect("new-sample", self.new_sample_handler)
		assert handler_id > 0
		handler_id = appsink.connect("eos", self.eos_handler)
		assert handler_id > 0
		self.appsinks[appsink] = None
		_, instrument, channel = appsink.name.split("_", 2)
		self.sink_dict.setdefault(appsink, "%s:%s" % (instrument, channel))
		return appsink
	
	def pull_buffers(self, elem):
		"""
		for internal use.  must be called with lock held.
		"""
		# keep looping while we can process buffers
		while 1:
			# retrieve the timestamps of all elements that
			# aren't at eos and all elements at eos that still
			# have buffers in them
			timestamps = [(t, e) for e, t in self.appsinks.items() if e not in self.at_eos or t is not None]
			# if all elements are at eos and none have buffers,
			# then we're at eos
			if not timestamps:
				return Gst.FlowReturn.EOS
			# find the element with the oldest timestamp.  None
			# compares as less than everything, so we'll find
			# any element (that isn't at eos) that doesn't yet
			# have a buffer (elements at eos and that are
			# without buffers aren't in the list)
			timestamp, elem_with_oldest = min(timestamps)
			# if there's an element without a buffer, quit for
			# now --- we require all non-eos elements to have
			# buffers before proceding
			if timestamp is None:
				return Gst.FlowReturn.OK
			# clear timestamp and pass element to handler func.
			# function call is done last so that all of our
			# book-keeping has been taken care of in case an
			# exception gets raised
			self.appsinks[elem_with_oldest] = None
			self.appsink_new_buffer(elem_with_oldest, self.sink_dict)

####################
# 
#       main
#
####################   

  
# parsing and setting up some core structures
options, filenames = parse_command_line()

data_source_info = multichannel_datasource.DataSourceInfo(options)
instrument, = data_source_info.channel_dict
channels = data_source_info.channel_dict[instrument].keys()

# building the event loop and pipeline
mainloop = GObject.MainLoop()
pipeline = Gst.Pipeline(sys.argv[0])
handler = MultiChannelHandler(mainloop, pipeline, out_file = options.out_file, out_path = options.out_path)

# multiple channel src
head = multichannel_datasource.mkbasicmultisrc(pipeline, data_source_info, instrument, verbose = options.verbose)

for channel in channels:
	samp_rate = data_source_info.channel_dict[instrument][channel]   
	print >>sys.stderr, "test " + instrument + " " + channel
	head[channel] = idq_multirate_datasource.mkwhitened_multirate_src(pipeline, head[channel], [samp_rate], instrument, channel_name = channel, width=32)[samp_rate]
	head[channel] = pipeparts.mkfirbank(pipeline, head[channel], fir_matrix = numpy.ones((2,1)), time_domain = True)
	head[channel] = pipeparts.mktogglecomplex(pipeline, head[channel])
	head[channel] = pipeparts.mkcapsfilter(pipeline, head[channel], caps = "audio/x-raw, format=Z64LE, rate=%i" % int(samp_rate))
	head[channel] = pipeparts.mktaginject(pipeline, head[channel], "instrument=%s,channel-name=%s" %( instrument, channel) )
	head[channel] = pipeparts.mktrigger(pipeline, head[channel], int(samp_rate), autocorrelation_matrix = numpy.ones((1,21), dtype=numpy.complex))
	head[channel] = pipeparts.mkqueue(pipeline, head[channel])

if options.verbose:
	print >>sys.stderr, "attaching appsinks to pipeline..."
appsync = LinkedAppSync(appsink_new_buffer = handler.bufhandler)
appsinks = set(appsync.add_sink(pipeline, head[channel], name = "sink_%s_%s" % (instrument, channel)) for channel in channels) 

  
# Allow Ctrl+C or sig term to gracefully shut down the program for online
# sources, otherwise it will just kill it
if data_source_info.data_source in ("lvshm", "framexmit"):# what about nds online?
	simplehandler.OneTimeSignalHandler(pipeline)

# Seek
if pipeline.set_state(Gst.State.READY) == Gst.StateChangeReturn.FAILURE:
	raise RuntimeError("pipeline failed to enter READY state")
if data_source_info.data_source not in ("lvshm", "framexmit"):# what about nds online?
	datasource.pipeline_seek_for_gps(pipeline, options.gps_start_time, options.gps_end_time)

# run
if pipeline.set_state(Gst.State.PLAYING) == Gst.StateChangeReturn.FAILURE:
	raise RuntimeError("pipeline failed to enter PLAYING state")
mainloop.run()
  
   
   
   
   
   
   
   
   
  
 
