#!/usr/bin/env python

# Copyright (C) 2017 Sydney J. Chamberlin, Patrick Godwin, Chad Hanna, Duncan Meacher
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.



####################
# 
#     preamble
#
####################   


from optparse import OptionParser
from collections import deque
import os
import sys
import StringIO

import gi
gi.require_version('Gst', '1.0')
from gi.repository import GObject, Gst
GObject.threads_init()
Gst.init(None)
import lal

import numpy
from gstlal import datasource
from gstlal import idq_multirate_datasource
from gstlal import multichannel_datasource
from gstlal import sngltriggertable
from gstlal import pipeparts
from gstlal import simplehandler
from glue.ligolw import utils as ligolw_utils

####################
# 
#    functions
#
####################   

#
# construct sine gaussian waveforms that taper to 1e-7 at edges of window
#
def duration(phi, q, tolerance = 1e-7):
        # return the duration of the waveform such that its edges will die out to tolerance of the peak.
	# phi is the central frequency of the frequency band
	return 2.*q/(2.*numpy.pi*phi)*numpy.log(1./tolerance)

def sine_gaussian(phi, phi_0, q, time_arr):
        # edges should be 1e-7 times peak
	dt = time_arr[1]-time_arr[0]
	rate = 1./dt
	assert phi < rate/2. 

	# phi is the central frequency of the sine gaussian
	dur = duration(phi,q)
	tau = q/(2.*numpy.pi*phi)
	sg_vals = numpy.cos(2.*numpy.pi*phi*time_arr + phi_0)*numpy.exp(-1.*time_arr**2./tau**2.)
	return sg_vals 

#
# number of tiles in frequency and Q
#
def N_Q(q_min, q_max, mismatch = 0.05):
        return numpy.ceil(1./(2.*numpy.sqrt(mismatch/3.))*1./numpy.sqrt(2)*numpy.log(q_max/q_min))

def N_phi(phi_min, phi_max, q,  mismatch = 0.05):
       return numpy.ceil(1./(2.*numpy.sqrt(mismatch/3.))*(numpy.sqrt(2.+q**2.)/2.)*numpy.log(phi_max/phi_min))

def Qq(q_min, q_max, mismatch = 0.05):
	N_q = numpy.ceil(N_Q(q_min, q_max, mismatch))
	return [q_min*(q_max/q_min)**((0.5+q)/N_q) for q in range(int(N_q))]

def phi_ql(phi_min, phi_max, q_min, q_max, mismatch = 0.05):
	for q in Qq(q_min, q_max):
		nphi = N_phi(phi_min, phi_max, q)
		for l in range(int(nphi)):
			yield (phi_min*(phi_max/phi_min)**((0.5+l)/nphi), q)

def parse_command_line():

	parser = OptionParser(description = __doc__)

	#
	# First append the datasource common options
	#

	multichannel_datasource.append_options(parser)
	parser.add_option("--out-path", metavar = "path", default = ".", help = "Write to this path. Default = .")
	parser.add_option("--out-file", metavar = "filename", default = "output_triggers.trg", help = "Set the filename in which to save the output.")
	parser.add_option("-v", "--verbose", action = "store_true", help = "Be verbose.")

	#
	# parse the arguments and sanity check
	#

	options, filenames = parser.parse_args()

	return options, filenames

####################
# 
#      classes
#
####################   


class MultiChannelHandler(simplehandler.Handler):
	def __init__(self, *args, **kwargs):
		self.out_file = kwargs.pop("out_file")
		self.out_path = kwargs.pop("out_path")
                # if file already exists, delete it first
                # FIXME this may not be the most elegant solution,
                #       but it'll do for now
                try:
                        os.remove(os.path.join(self.out_path, self.out_file))
                except OSError:
                        pass
                # create header for trigger file
                #header = "# start_time stop_time time frequency unnormalized_energy normalized_energy chisqdof significance channel\n"
                header = "# %16s\t%16s\t%16s\t%4s\t%4s\t%16s\n" % ("end_time", "phase", "snr", "chisq", "sigmasq", "channel")
                self.to_trigger_file(os.path.join(self.out_path, self.out_file), header)
		
		super(MultiChannelHandler, self).__init__(*args, **kwargs)

	def do_on_message(self, bus, message):
		return False

	def bufhandler(self, elem, sink_dict):
		buf = elem.emit("pull-sample").get_buffer()
		buftime = int(buf.pts / 1e9)
		channel = sink_dict[elem]
		fdata = ""	
		for i in range(buf.n_memory()):
			memory = buf.peek_memory(i)
			result, mapinfo = memory.map(Gst.MapFlags.READ)
			assert result
			# NOTE NOTE NOTE NOTE
			# It is critical that the correct class'
			# .from_buffer() method be used here.  This
			# code is interpreting the buffer's
			# contents as an array of C structures and
			# building instances of python wrappers of
			# those structures but if the python
			# wrappers are for the wrong structure
			# declaration then terrible terrible things
			# will happen
			if mapinfo.data:
				for row in sngltriggertable.GSTLALSnglTrigger.from_buffer(mapinfo.data):
					fdata += "%18s\t%18s\t%18s\t%s\t%s\t%s\n" % (row.end_time + row.end_time_ns*1e-9, row.phase, row.snr, row.chisq, row.sigmasq, channel)
			memory.unmap(mapinfo)

		# Save a "latest"
		self.to_trigger_file(os.path.join(self.out_path, self.out_file), fdata)
		
		del buf
		return Gst.FlowReturn.OK

	def to_trigger_file(self, path, data):
		with open(path, 'a') as f:
 			f.write(data)


class LinkedAppSync(pipeparts.AppSync):
	def __init__(self, appsink_new_buffer, sink_dict = {}):
		super(LinkedAppSync, self).__init__(appsink_new_buffer, sink_dict.keys())
		self.sink_dict = sink_dict	
	
	def attach(self, appsink):
		"""
		connect this AppSync's signal handlers to the given appsink
		element.  the element's max-buffers property will be set to
		1 (required for AppSync to work).
		"""
		if appsink in self.appsinks:
			raise ValueError("duplicate appsinks %s" % repr(appsink))
		appsink.set_property("max-buffers", 1)
		handler_id = appsink.connect("new-preroll", self.new_preroll_handler)
		assert handler_id > 0
		handler_id = appsink.connect("new-sample", self.new_sample_handler)
		assert handler_id > 0
		handler_id = appsink.connect("eos", self.eos_handler)
		assert handler_id > 0
		self.appsinks[appsink] = None
		_, instrument, channel = appsink.name.split("_", 2)
		self.sink_dict.setdefault(appsink, "%s:%s" % (instrument, channel))
		return appsink
	
	def pull_buffers(self, elem):
		"""
		for internal use.  must be called with lock held.
		"""

		while 1:
			# time ordering:
			# retrieve the timestamps of all elements that
			# aren't at eos and all elements at eos that still
			# have buffers in them
			#timestamps = [(t, e) for e, t in self.appsinks.items() if e not in self.at_eos or t is not None]
			# if all elements are at eos and none have buffers,
			# then we're at eos
			#if not timestamps:
			#	return Gst.FlowReturn.EOS
			# find the element with the oldest timestamp.  None
			# compares as less than everything, so we'll find
			# any element (that isn't at eos) that doesn't yet
			# have a buffer (elements at eos and that are
			# without buffers aren't in the list)
			#timestamp, elem_with_oldest = min(timestamps)
			# if there's an element without a buffer, quit for
			# now --- we require all non-eos elements to have
			# buffers before proceding
			#if timestamp is None:
			#	return Gst.FlowReturn.OK
			# clear timestamp and pass element to handler func.
			# function call is done last so that all of our
			# book-keeping has been taken care of in case an
			# exception gets raised
			#self.appsinks[elem_with_oldest] = None
			#self.appsink_new_buffer(elem_with_oldest, self.sink_dict)
		
			# no time ordering:
			if not elem in self.appsinks:
				return Gst.FlowReturn.EOS
			if self.appsinks[elem] is None:
				return Gst.FlowReturn.OK
			self.appsinks[elem] = None
			self.appsink_new_buffer(elem, self.sink_dict)


####################
# 
#       main
#
####################   

  
# parsing and setting up some core structures
options, filenames = parse_command_line()

data_source_info = multichannel_datasource.DataSourceInfo(options)
instrument = data_source_info.instrument
channels = data_source_info.channel_dict.keys()

# building the event loop and pipeline
mainloop = GObject.MainLoop()
pipeline = Gst.Pipeline(sys.argv[0])
handler = MultiChannelHandler(mainloop, pipeline, out_file = options.out_file, out_path = options.out_path)

# multiple channel src
head = multichannel_datasource.mkbasicmultisrc(pipeline, data_source_info, instrument, verbose = options.verbose)
src = {}
for channel in channels:
	samp_rate = data_source_info.channel_dict[channel]['fsamp']  
	max_samp_rate = samp_rate 
	min_samp_rate = min(32., max_samp_rate)
	n_rates = int(numpy.log2(max_samp_rate/min_samp_rate) + 1)
	for rate, thishead in idq_multirate_datasource.mkwhitened_multirate_src(pipeline, head[channel], [min_samp_rate*2.**i for i in range(n_rates)], instrument, channel_name = channel, width=32).items():
		# FIXME: don't hardcode q and frequency
		flow = rate/4.*0.8
		fhigh = rate/2.*0.8
		qlow = 4
		qhigh = 40
		# omicron params, make sure to use .INI file before uncommenting
		#flow = data_source_info.channel_dict[channel]['flow']  
		#fhigh = data_source_info.channel_dict[channel]['fhigh']  
		#qhigh = data_source_info.channel_dict[channel]['qhigh']  
		dur = max([duration(phi, q) for (phi, q) in phi_ql(flow, fhigh, qlow, qhigh)])
		t_arr = numpy.linspace(-dur/2., dur/2., int(dur*rate))
		phase = [0, numpy.pi/2.]
		thishead = pipeparts.mkfirbank(pipeline, thishead, fir_matrix = numpy.array([sine_gaussian(phi, phi_0, q, t_arr) for (phi, q) in phi_ql(flow, fhigh, qlow, qhigh) for phi_0 in phase]), time_domain = False, block_stride = int(rate))
		#thishead = pipeparts.mkfirbank(pipeline, thishead, fir_matrix = numpy.ones((2,1)), time_domain = True)
		thishead = pipeparts.mktogglecomplex(pipeline, thishead)
		thishead = pipeparts.mkcapsfilter(pipeline, thishead, caps = "audio/x-raw, format=Z64LE, rate=%i" % int(rate))
		thishead = pipeparts.mktaginject(pipeline, thishead, "instrument=%s,channel-name=%s" %( instrument, channel) )
		thishead = pipeparts.mktrigger(pipeline, thishead, int(rate))
		#thishead = pipeparts.mktrigger(pipeline, thishead, int(rate), autocorrelation_matrix = numpy.ones((len(list(phi_ql(flow, fhigh, qlow, qhigh))), 21), dtype=numpy.complex))
		thishead = pipeparts.mkqueue(pipeline, thishead)
		src[(channel, rate)] = thishead	

if options.verbose:
	print >>sys.stderr, "attaching appsinks to pipeline..."
appsync = LinkedAppSync(appsink_new_buffer = handler.bufhandler)
appsinks = set(appsync.add_sink(pipeline, src[x], name = "sink_%s_%s" % x) for x in src.keys()) 
  
# Allow Ctrl+C or sig term to gracefully shut down the program for online
# sources, otherwise it will just kill it
if data_source_info.data_source in ("lvshm", "framexmit"):# what about nds online?
	simplehandler.OneTimeSignalHandler(pipeline)

# Seek
if pipeline.set_state(Gst.State.READY) == Gst.StateChangeReturn.FAILURE:
	raise RuntimeError("pipeline failed to enter READY state")
if data_source_info.data_source not in ("lvshm", "framexmit"):# what about nds online?
	datasource.pipeline_seek_for_gps(pipeline, options.gps_start_time, options.gps_end_time)

# run
if pipeline.set_state(Gst.State.PLAYING) == Gst.StateChangeReturn.FAILURE:
	raise RuntimeError("pipeline failed to enter PLAYING state")
mainloop.run()
  
   
   
   
   
   
   
   
   
  
 
