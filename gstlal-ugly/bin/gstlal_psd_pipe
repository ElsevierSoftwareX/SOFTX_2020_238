#!/usr/bin/env python3
#
# Copyright (C) 2012 Chad Hanna
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

"""
This program makes a dag to run a psd estimation dag
"""

__author__ = 'Chad Hanna <channa@caltech.edu>'

##############################################################################
# import standard modules and append the lalapps prefix to the python path
import sys, os

##############################################################################
# import the modules we need to build the pipeline
from ligo import segments
from optparse import OptionParser
from gstlal import dagparts
from gstlal import datasource

#
# Classes for generating reference psds
#

def set_up_jobs(options):
	jobs = {}

	# default condor options
	default_condor_opts = {
		'want_graceful_removal': "True",
		'kill_sig': "15",
		'request_memory': "2000"
	}

	# job-specific condor options
	ref_psd_condor_opts = default_condor_opts.copy()
	ref_psd_condor_opts['request_cpus'] = "2"

	# set condor commands
	base_condor_commands = dagparts.condor_command_dict_from_opts(options.condor_command, default_condor_opts)
	ref_psd_condor_commands = dagparts.condor_command_dict_from_opts(options.condor_command, ref_psd_condor_opts)

	jobs['refPSD'] = dagparts.DAGJob("gstlal_reference_psd", condor_commands = ref_psd_condor_commands)
	jobs['medianPSD'] = dagparts.DAGJob("gstlal_median_of_psds", condor_commands = base_condor_commands)

	return jobs


def parse_command_line():
	parser = OptionParser(description = __doc__)

	# generic data source options
	datasource.append_options(parser)

	parser.add_option("--max-segment-length", type="int", metavar = "dur", default = 30000, help = "Break up segments longer than dur seconds into shorter (contiguous, non-overlapping) segments. Default 30000 seconds.")
	parser.add_option("--condor-command", action = "append", default = [], metavar = "command=value", help = "set condor commands of the form command=value; can be given multiple times")
	parser.add_option("--verbose", action = "store_true", help = "Be verbose")

	options, filenames = parser.parse_args()

	return options, filenames


#
# MAIN
#

options, filenames = parse_command_line()

detectors = datasource.GWDataSourceInfo(options)
channel_dict = detectors.channel_dict

#
# Setup analysis segments
#

segs = detectors.frame_segments

# union of all single detector segments that we want to analyze
segs = segs.union(channel_dict.keys()).coalesce()

# intersect so we only analyze segments in the requested time 
boundary_seg = detectors.seg
segs &= segments.segmentlist([boundary_seg])

# FIXME break up long segments into smaller ones with 1024 of overlap
segs = dagparts.breakupsegs(segs, options.max_segment_length, 1024)

try: os.mkdir("logs")
except: pass
dag = dagparts.DAG("psd_pipe")

#
# setup the job classes
#

jobs = set_up_jobs(options)

#
# Precompute the PSDs for each segment
#

def hash_seg(seg):
	# FIXME what is a good way to hash the segment?
	return str(seg)

psd_nodes = {}
for seg in segs:
	psd_nodes[hash_seg(seg)] = dagparts.DAGNode(jobs['refPSD'], dag,
		parent_nodes = [],
		opts = {
			"gps-start-time": int(seg[0]),
			"gps-end-time": int(seg[1]),
			"data-source": "frames",
			"channel-name": datasource.pipeline_channel_list_from_channel_dict(channel_dict),
			"frame-segments-name": options.frame_segments_name
		},
		input_files = {
			"frame-cache": options.frame_cache,
			"frame-segments-file": options.frame_segments_file
		},
		output_files = {
			"write-psd": dagparts.T050017_filename("".join(sorted(channel_dict)), "REFERENCE_PSD", seg, '.xml.gz', path = os.getcwd())
		},
	)

median_psd_node = dagparts.DAGNode(jobs['medianPSD'], dag,
	parent_nodes = psd_nodes.values(),
	input_files = {"": [node.output_files["write-psd"] for node in psd_nodes.values()]},
	output_files = {"output-name": "median_psd.xml.gz"}
)

dag.write_sub_files()
dag.write_dag()
dag.write_script()
dag.write_cache()
