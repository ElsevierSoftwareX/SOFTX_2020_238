#!/usr/bin/env python
#
# Copyright (C) 2011 Chris Pankow
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
"""Stream-based burst analysis tool"""

#
# =============================================================================
#
#                                   Preamble
#
# =============================================================================
#


import os
import numpy
import signal

from optparse import OptionParser
import ConfigParser
from ConfigParser import SafeConfigParser

from gstlal.pipeutil import gst, mkelem
from gstlal.pipeparts import *
from gstlal.pipeio import parse_spectrum_message
from gstlal.lloidparts import LLOIDHandler, DetectorData, mkLLOIDbasicsrc

import gstlal.excesspower as ep
from gstlal.excesspower import *
from gstlal.inspiral import add_cbc_metadata

#from ep_utils import duration_from_cache

from glue.ligolw import ligolw
from glue.ligolw import lsctables
from glue.ligolw import utils
from glue.ligolw.utils import process as ligolw_process

from glue.segments import segment
from glue import gpstime
from glue.lal import LIGOTimeGPS

from pylal.xlal.datatypes.snglburst import from_buffer as sngl_bursts_from_buffer
from pylal.xlal.datatypes.real8frequencyseries import REAL8FrequencySeries

#
# =============================================================================
#
#                                Handler Class
#
# =============================================================================
#

GSTLAL_VALID_FREQ_UNITS = {
	"Mhz": 1e6,
	"kHz": 1e3,
	"Hz": 1.0,
	"mHz": 1e-3,
	"uHz": 1e-6
}


class EPHandler( LLOIDHandler ):
	"""
	Handler class for the excess power pipeline. Keeps various bits of information that the pipeline emits and consumes. This is also in charge of signalling the rebuild of various matrices and vectors needed by the pipeline.
	"""
	def __init__( self, mainloop, pipeline ):

		# Instrument and channel
		self.inst = None
		self.channel = None

		# Book keeping
		self.start = 0
		self.stop = -1

		# Defaults -- Time-frequency map settings
		self.base_band = 16
		self.flow = 64 
		self.fhigh = 1000
		#self.fhigh = 2000

		# Defaults -- Resolution settings
		self.rate = 2048
		#self.rate = 4096
		self.max_level = 1

		# Defaults -- filtering
		self.filter_len = 2*int(2*self.rate/self.base_band)
		self.filter_bank = None
		# TODO: Maybe not necessary
		self.firbank = None

		# Defaults -- PSD settings
		# This is used to store the previous value of the PSD power
		self.psd_power = 0
		self.cache_psd = False
		self.psd_change_thresh = 0.5 # fifty percent

		# Defaults -- Two-point spectral correlation settings
		self.cache_spec_corr = False

		# Defaults -- mixer matrices
		self.chan_matrix = None
		self.mmixers = {}

		# Defaults -- injections
		# TODO: Scheduled for deletion
		#self.unicorns = False

		# Defaults -- data products
		self.output = True
		self.triggers = None
		self.outfile = "test.xml"
		self.make_output_table()
		self.snr_thresh = 5.5
		self.fap = None
		self.dump_frequency = 600 # s
		self.max_events = 1e3
		self.time_since_dump = self.start

		self.trigger_segment = None

		self.spec_corr = self.build_default_correlation( self.rate )
		"""
		self.psd = self.build_default_psd( self.rate, self.filter_len )
		self.rebuild_filter()
		self.rebuild_chan_mix_matrix()
		"""

		self.bus = pipeline.get_bus()
		self.bus.add_signal_watch()
		self.bus.connect( "message", self.process_message )

		super(type(self), self).__init__(mainloop, pipeline)

	def set_trigger_time_and_action( self, trig_seg, action=["psd"] ):
		"""
		Inform the handler of a specific time of interest.
		"""
		# TODO: Bounds checking
		self.trigger_segment = trig_seg

		# TODO: Handle only specific action requests

	def process_message( self, bus, message ):
		"""
		Process a message from the bus. Depending on what it is, we may drop various data products on to disk.
		"""
		if( message.type == gst.MESSAGE_EOS ):
			self.shutdown(None, None)
			return
		else:
			pass
			# TODO: How to send messages to the gst debug stream

		if( message.structure is None and message.type == gst.MESSAGE_EOS ):
			print >>sys.stderr, "WARNING: Received invalid message."
			return

		if( message.structure.get_name() == "spectrum" ):
			ts = message.structure[ "timestamp" ]*1e-9
			if( self.trigger_segment is not None 
				and ts in self.trigger_segment ):
				self.dump_psd("spectrum_data.dat")
			elif( self.cache_psd ):
				self.dump_psd("spectrum_data.dat")

	def dump_psd( self, filename, asd=False ):
		"""
		Dump the currently cached PSD to a text file.
		"""
		# TODO: Better format for this?
		print >>sys.stderr, "Outputting PSD to psd.dat"
		f = open("psd.dat", "w")
		for freq, p in enumerate( self.psd.data ):
			f.write("%f %g\n" % (freq*self.psd.deltaF, p) )
		f.close()

	def add_firbank( self, firbank ):
		"""
		Set the main base band FIR bank, and build the FIR matrix.
		"""
		self.firbank = firbank
		firbank.set_property( "fir-matrix", self.rebuild_filter() )

	def add_matmixer( self, mm, res_level ):
		self.mmixers[ res_level ] = mm
		self.rebuild_matrix_mixers( res_level )

	def build_default_psd( self, rate, filter_len ):
		"""
		Builds a dummy PSD to use until we get the right one.
		"""
		psd = REAL8FrequencySeries()
		psd.deltaF = float(rate)/filter_len
		psd.data = numpy.ones( filter_len/2 + 1 ) #/ 2 / psd.deltaF
		psd.f0 = 0
		self.psd = psd
		return psd

	def build_default_correlation( self, rate ):
		"""
		Builds a Kronecker delta correlation series for k, k'.
		"""
		corr = numpy.zeros(rate + 1)
		corr[0] = 1
		return corr

	def rebuild_matrix_mixers( self, res_level = None ):
		"""
		Rebuilds the matrix mixer matrices from the coefficients calculated in rebuild_chan_mix_matrix and assigns them to their proper element.
		"""
		for i, mm in self.mmixers.iteritems():
			if( res_level != None and res_level != i ): continue

			nchannels = self.filter_bank.shape[0]
			up_factor = int(numpy.log2(nchannels/(nchannels >> i)))
			cmatrix = ep.build_chan_matrix( 
				nchannels = nchannels,
				up_factor = up_factor,
				norm = self.chan_matrix[i] 
			)
			mm.set_property( "matrix", cmatrix )

	def rebuild_filter( self ):
		"""
		Calling this function rebuilds the filter FIR banks and assigns them to their proper element. This is normally called when the PSD or spectrum correlation changes.
		"""
		self.filter_bank = ep.build_filter( fhigh = self.fhigh, flow=self.flow, psd = self.psd, corr = self.spec_corr, b_wind = self.base_band )
		return self.filter_bank

	def build_filter_xml( self, res_level, loc="" ):
		"""
		Calls the EP library to create a XML of sngl_burst tables representing the filter banks. At the moment, this dumps them to the current directory, but this can be changed by supplying the 'loc' argument. The written filename is returned for easy use by the trigger generator.
		"""
		self.filter_xml = ep.create_bank_xml(
			self.flow,
			self.fhigh,
			self.base_band,
			# FIXME: Is there a factor of two here?
			1.0 / (2*self.base_band*(res_level+1)), # resolution level starts from 0
			self.inst
		)
		output = "%sgstlal_excesspower_bank_%s_%s_level_%d.xml" % (loc, self.inst, self.channel, res_level)
		utils.write_filename( self.filter_xml, output, verbose = True,
		       gz = (output or "stdout").endswith(".gz") )
		return output

	def destroy_filter_xml( self, loc="" ):
		import glob
		for f in glob.glob( "%s/gstlal_excesspower_bank_%s_level_*.xml" % (loc, self.inst) ):
			os.rm( f )

	def rebuild_chan_mix_matrix( self ):
		"""
		Calling this function rebuilds the matrix mixer coefficients for higher resolution components. This is normally called when the PSD or spectrum correlation changes.
		"""
		self.chan_matrix = ep.build_inner_product_norm( 
			corr = self.spec_corr, 
			band = self.base_band, 
			del_f = self.psd.deltaF,
			nfilts = len(self.filter_bank),
			flow = self.flow,
			# TODO: PSD option to lalburst IP doesn't work
			#psd = self.psd
			max_level = self.max_level
		)
		return self.chan_matrix

	def rebuild_everything( self ):
		"""
		Top-level function to handle the asynchronous updating of FIR banks and matrix mixer elements.
		"""
		# Rebuild filter bank and hand it off to the FIR element
		print >> sys.stderr, "Rebuilding FIR bank"
		self.firbank.set_property( "fir_matrix", self.rebuild_filter() )

		print >> sys.stderr, "Rebuilding matrix mixer"
		self.rebuild_chan_mix_matrix()
		# Rebuild the matrix mixer with new normalization coefficients
		self.rebuild_matrix_mixers()

	def make_output_table( self ):
		self.triggers = lsctables.New(lsctables.SnglBurstTable,
			["ifo", "peak_time", "peak_time_ns", "start_time", "start_time_ns",
			"duration",  "search", "event_id",
			"central_freq", "channel", "amplitude", "snr", "confidence",
			"chisq", "chisq_dof", "bandwidth"])
			#"peak_frequency",
			#"stop_time", "peak_time_ns", "start_time_ns", "stop_time_ns",
 			#"time_lag", "flow", "fhigh", tfvolume, hrss, process_id
		return self.triggers

	def write_triggers( self, flush=True, overwrite=False, filename=None ):

		if( filename == None ):
			filename = self.outfile

		output = ligolw.Document()
		output.appendChild(ligolw.LIGO_LW())
		output.childNodes[0].appendChild( self.triggers )

		# TODO: Before or after Paused?
		analysis_segment = segment(
			LIGOTimeGPS( self.start ), 
			LIGOTimeGPS( self.stop )
		)
		# TODO: Define a difference between what was requested and what was analyzed
		requested_segment = analysis_segment

		process_params = vars( options )
		#import pdb
		#pdb.set_trace()
		process = ligolw_process.register_to_xmldoc( output, "gstlal_excesspower", vars(options) )#, ifos = self.inst )
		add_cbc_metadata( output, process, requested_segment, analysis_segment )
		# TODO: replace cbc filter table with our own
		#cbc_filter_table = lsctables.getTablesByType( output, lsctables.FilterTable )[0]
		#ep_filter_table = lsctables.getTablesByType( self.filter_xml, lsctables.FilterTable )[0]
		#output.replaceChild( ep_filter_table, cbc_filter_table )
		print >>sys.stderr, "Outputting triggers for %s\n" % str(analysis_segment)

		# FIXME:  the signal.signal() function is
		# disabled for the duration of the
		# .write_fileobj() call to work around some
		# threading problems.  Glue should be
		# modified to make signal trapping optional
		# so that this isn't needed.  Remove when
		# that's taken care of.
		#
		# write the new distribution stats to disk
		lock = threading.Lock()
		lock.acquire()
		orig_signal = utils.signal.signal
		utils.signal.signal = lambda *args: None
		# Enable to debug LIGOLW stream
		#utils.write_fileobj(output, sys.stdout)
		utils.write_filename(output, filename, verbose = options.verbose)
         #gz = (output or "stdout").endswith(".gz"))
		utils.signal.signal = orig_signal
		lock.release()
		# End FIXME

		if( flush ): self.make_output_table()

	def shutdown( self, signum, frame ):
		"""
		Method called to flush buffers and shutdown the pipeline.
		"""
		print >>sys.stderr, "Caught signal: dying a terrible, terrible death."
		print "Signal received, if any: " + str(signum)
		self.pipeline.set_state( gst.STATE_PAUSED )
		bus = self.pipeline.get_bus()
		bus.post(gst.message_new_eos(pipeline))
		self.pipeline.set_state( gst.STATE_NULL )
		self.mainloop.quit()

		print >>sys.stderr, "Please wait (don't ctrl+c) while I dump triggers to disk."
		dur = int( handler.stop - handler.time_since_dump + 0.5 )
		outfile = self.outfile or "%s_%s_triggers_%d_%d.xml" % (handler.inst, handler.channel, handler.time_since_dump, dur)
		self.write_triggers( False, filename = outfile )
		self.destroy_filter_xml()

	def cmd_line( self, signum, frame ):
		"""
		Basic attempt to control the pipline while in operation. However, the pipeline seems unable to change state, so for the time being, this does nothing.
		"""
		print >>sys.stderr, "Attempting to pause pipeline..."
		self.pipeline.set_state( gst.STATE_PAUSED )
		if( self.pipeline.get_state() != gst.STATE_PAUSED ): 
			print >>sys.stderr, "failed."
			return
		else:
			print >>sys.stderr, "success!"

		while( True ):
			inp = raw_input("gst_ep, proc=() $ ")
			print inp
			if( inp.strip() == "continue" ): 
				self.pipeline.set_state( gst.STATE_PLAYING )
				break
			elif( inp.strip() == "quit" ): 
				gst.message_new_eos( self )


#
# =============================================================================
#
#                        Message Handler Methods
#
# =============================================================================
#

# These are linked later in the pipeline to do the appropriate actions when signals are sent up.

def on_psd_change( elem, pspec, hand ):
	"""
	Get the PSD object and signal the handler to rebuild everything.
	"""
	print >> sys.stderr, "Intercepted spectrum signal."

	hand.psd = REAL8FrequencySeries(
		name = "PSD",
		#epoch = laltypes.LIGOTimeGPS(0, message.structure["timestamp"]),
		f0 = 0.0,
		deltaF = elem.get_property( "delta-f" ),
		#sampleUnits = laltypes.LALUnit(message.structure["sample-units"].strip()),
		data = numpy.array( elem.get_property( "mean-psd" ) )
	)


	# Determine if the PSD has changed enough to warrant rebuilding the filter
	# bank.
	psd_power = sum(hand.psd.data)
	change = abs((hand.psd_power - psd_power) / psd_power )
	if( change > 0.5 ):
		print >> sys.stderr, "Processed signal. PSD change %d per, regenerating filters" % int(change*100)
		hand.psd_power = psd_power
		hand.rebuild_everything()

def on_spec_corr_change( elem, pspec, hand ):
	"""
	Get the 2-point spectral correlation object and signal the handler to rebuild everything.
	"""
	print >> sys.stderr, "Intercepted correlation signal."
	hand.spec_corr = elem.get_property( "spectral-correlation" )

	if( hand.cache_spec_corr ):
		f = open( "spec_corr.dat", "w" )
		k_end = len( hand.spec_corr ) / 2
		for k, sp in enumerate( hand.spec_corr ):
			f.write( "%d %g\n" % (k, sp) )
	
	# If the spectrum correlation changes, rebuild everything
	if( hand.psd != None ):
		hand.rebuild_everything()

def get_triggers(elem, handler, ndof):

	buffer = elem.emit("pull-buffer")

	if( not handler.output ):
		return # We don't want event information

	for row in sngl_bursts_from_buffer(buffer):
		row.duration *= ndof
		if( options.compat ):
			row.snr = row.snr / ndof - 1
		handler.triggers.append( row )
	
	handler.stop = (buffer.timestamp + buffer.duration)*1e-9
	if( handler.stop - handler.time_since_dump > handler.dump_frequency or
			len(handler.triggers) >= handler.max_events ):
		dur = int( handler.stop - handler.time_since_dump + 0.5 )
		handler.write_triggers( filename = "%s_%s_triggers_%d_%d.xml" % (handler.inst, handler.channel, handler.time_since_dump, dur), flush = True )
		handler.time_since_dump = handler.stop 

# TODO: Update a single file every couple of seconds.
"""
	dur = 0
	if( len(handler.triggers) > 0 ):
		dur = handler.triggers[-1].peak_time - handler.triggers[0].peak_time

	if( len(handler.triggers) > 1000 or dur > 16 ):
		handler.write_triggers( flush=True )
"""

#
# =============================================================================
#
#                             Options Handling
#
# =============================================================================
#

parser = OptionParser()
parser.add_option("-f", "--initialization-file", dest="infile", help="Options to be pased to the pipeline handler. Strongly recommended.", default=None)
parser.add_option("-d", "--diagnostics", dest="diagnostics", action="store_true", help="Turn on multiple diagnostic dumps. Use with caution, as it will dump gigabytes of data (potentially) in a matter of minutes. Useful in nongraphical environemnts to monitor data throughput.", default=False)
parser.add_option("-v", "--verbose", dest="verbose", action="store_true", help="Be verbose.", default=False)
parser.add_option("-n", "--channel-name", dest="channame", action="store", help="Specify the channel name. Note that this will override the specification in the ini file (if any). This is useful if you want to run the same analysis on channels with the same characterisitics.")
parser.add_option("-w", "--channel-width", dest="nbyte", action="store", type=int, help="Specify the channel width in bits (default = 64)", default=64)
parser.add_option("-r", "--sample-rate", dest="sample_rate", action="store", type="int", help="Sample rate of the incoming data.")
parser.add_option("-D", "--data-source", dest="data_source", action="store", help="Data source to read from. Valid options are gwffile,lldata,whitedata,fakeLIGO,fakeadvLIGO. One is required. If gwffile is selected, then a cache file should also be provided. If whitedata, fakeLIGO, or fakeadvLIGO is selected, then a sample rate must also be provided.")
parser.add_option("-S", "--stream-tfmap", dest="stream_tfmap", action="store", help="Encode the time frequency map to video as it is analyzed. If the argument to this option is \"video\" then the pipeline will attempt to stream to a video source. If the option is instead a filename, the video will be sent to that name. Prepending \"keyframe=\" to the filename will start a new video every time a keyframe is hit.")
parser.add_option("-u", "--unicorns", dest="unicorns", action="store", help="Reveal hidden unicorns in data. The argument to this option determines how strong said unicorns are.", default=None)
parser.add_option("-s", "--gps-start", dest="gps_start", action="store", type="float", help="Seek to gps time before beginning analysis.", default=None)
parser.add_option("-e", "--gps-end", dest="gps_end", action="store", type="float", help="End the analysis at this gps time.", default=None)
parser.add_option("-t", "--disable-triggers", dest="disable_triggers", action="store_false", help="Don't record triggers.", default=False)
parser.add_option("-c", "--lalapps-power-compatibility", dest="compat", action="store_true", default=False, help="Output trigger information which conforms to the lalapps_power conventions.")

(options, args) = parser.parse_args()

# The data rate at which we wish to do analysis
# Assumed lower than the input data
data_source = options.data_source

# TODO: Stop reinventing the wheel and replace this with mkLLOIDsrc
valid_data_sources = [ "gwffile", 
	  "lldata", 
	  "whitedata", 
	  "fakeLIGO", 
	  "fakeadvLIGO" ]
if( not data_source in valid_data_sources ):
	print >>sys.stderr, "Either no data soruce was selected, or an invalid one was requested."
	sys.exit(-1)

if( not options.sample_rate 
	and ( data_source in ["whitedata", "fakeLIGO", "fakeadvLIGO"] ) ):
	print >>sys.stderr, "Sample rate not specified and fake data requested."
	sys.exit(-1)
else:
	sample_rate = options.sample_rate

# Verbosity and diagnostics
verbose = options.verbose
diagnostics = options.diagnostics

# UNICORNS!!!!!!!!!!11!
unicorns, unicorn_volume = False, 0
if( options.unicorns ):
	unicorns = True
	unicorn_volume = options.unicorns 

#
# =============================================================================
#
#                           Handler / Pipeline options
#
# =============================================================================
#

# We need a pipeline and pipeline handler instance to configure
pipeline = gst.Pipeline( "gstlal_excesspower" )
mainloop = gobject.MainLoop()
handler = EPHandler(mainloop, pipeline)

handler.output = not options.disable_triggers
handler.rate = options.sample_rate

if( not options.infile ):
	print >>sys.stderr, "No initialization file specified. Default values will be used."
elif( not os.path.exists( options.infile ) ):
	print >>sys.stderr, "Initialization file path is invalid."
	sys.exit(-1)
else:
	cfg = SafeConfigParser()
	cfg.read( options.infile )

	# Handler options
	handler.flow = cfg.getint( "tf_parameters", "min-frequency" )
	handler.fhigh = cfg.getint( "tf_parameters", "max-frequency" )
	handler.base_band = cfg.getfloat( "tf_parameters", "base-resolution" )
	handler.max_level = cfg.getint( "tf_parameters", "max-resolution-level" )
	handler.max_duration = cfg.getfloat( "tf_parameters", "max-time-resolution" )
	handler.cache_spec_corr = cfg.getboolean( "cache", "cache-spectral-correlation" )
	handler.cache_psd = cfg.getboolean( "cache", "cache-psd" )

	handler.outfile = cfg.get( "triggering", "output-file" )
	handler.snr_thresh = cfg.getfloat( "triggering", "snr-thresh" )

	# If a specific (trigger) time is of interest, specify its GPS here
	# TODO: Read from sngl_inspirals and sngl_bursts
	trigger_begin, trigger_end = None, None
	if( cfg.has_option( "triggering", "trig_time_start" ) ):
		trigger_begin = cfg.getfloat( "triggering", "trig_time_start" )
	if( cfg.has_option( "triggering", "trig_time_end" ) ):
		trigger_end = cfg.getfloat( "triggering", "trig_time_end" )
	if( trigger_begin and trigger_end ):
		handler.set_trigger_time_and_action( segment( trigger_begin, trigger_end ) )

	# Instruments and channels
	handler.inst = cfg.get( "instrument", "detector" )
	try:
		handler.channel = cfg.get( "instrument", "channel" )
	except ConfigParser.NoOptionError:
		handler.channel = None

	if( options.channame is not None ):
		handler.channel = options.channame
	if( handler.channel is None ):
		exit("No channel specified in the configuration file or on the command line.")
	print "Channel name: " + handler.channel

	try:
		site = cfg.get( "instrument", "site" )
	except ConfigParser.NoOptionError:
		print >>sys.stderr, "No site requested, using detector as default cache sieve."
		site = None
	gwflocation = cfg.get( "instrument", "location" )

	inj_loc = cfg.get( "injections", "xml-location" )
	if( not os.path.isfile( inj_loc ) ):
		print >>sys.stderr, "Injection file not found, disabling option."
		inj_loc = None

base_band = handler.base_band

# This is invoked here, or else the default rate is used, which will cause funny behavior for the defaults with some cases
handler.build_default_psd( handler.rate, handler.filter_len )
handler.rebuild_filter()
handler.rebuild_chan_mix_matrix()

# Max trigger duration (s)
handler.max_duration

#
# =============================================================================
#
#                                     Main
#
# =============================================================================
#

if options.verbose:
	print >>sys.stderr, "Assembling pipeline...\n",

duration = -1

# Data source
if( data_source == "fakeLIGO" ):
	head = mkfakeLIGOsrc( pipeline, 
		instrument = handler.inst,
		channel_name = handler.channel
	)
elif( data_source == "fakeadvLIGO" ):
	head = mkfakeadvLIGOsrc( pipeline, 
		instrument = handler.inst,
		channel_name = handler.channel
	)
elif( data_source == "whitedata" ):
	head = gst.element_factory_make( "audiotestsrc" )
	pipeline.add( head )
	head.set_property( "wave", 9 ) # unity variance zero mean gaussian noise
elif( data_source == "lldata" ):
	head = mkLLOIDbasicsrc( pipeline, 
		None, 
		handler.inst, 
		DetectorData(None, handler.channel), 
		fake_data = None, 
		online_data = True, 
		injection_filename = inj_loc, 
		frame_segments = None, 
		verbose = True
	)
	# FIXME: This is a guess. Not a terrible one, but still inaccurate
	handler.time_since_dump = gpstime.GpsSecondsFromPyUTC( time.time() )
elif( data_source == "gwffile" ):
	framesrc = head = mkframesrc( pipeline, 
		gwflocation, 
		handler.inst, 
		handler.channel
	)
	start, duration = ep.duration_from_cache( gwflocation )
	if( options.gps_start ):
		handler.start = start = options.gps_start 
	else:
		options.gps_start = handler.start = start
		options.gps_start = float(options.gps_start)
	if( options.gps_end ):
		duration = options.gps_end - start
	else:
		options.gps_end = start + duration
		options.gps_end = float(options.gps_end)
	handler.time_since_dump = start
	# TODO: Must unhardcode this -- but requires knowledge of native rate
	if( options.nbyte == 64 ):
		bsize=16384*8 # 64 bit stream
	elif( options.nbyte == 32 ):
		bsize=16384*4 # 32 bit stream
	if( verbose ):
		print "Blocksize %d" % bsize
	#duration = int(duration*handler.rate/16384.0)
	head.set_property( "blocksize", bsize )
	print >>sys.stderr, "Warning, inferring analysis duration from cache."
	#print >>sys.stderr, "Buffers %d" % int(duration)
	#head.set_property( "num-buffers", int(duration) )

	# FIXME: Make this an option
	if( handler.inst == "V1" ): 
		sieve = "V*"
		head.set_property( "cache-dsc-regex", sieve )
	if( site ):
		sieve = site[0] + "*"
	else: sieve = handler.inst + "*"
	head.set_property( "cache-dsc-regex", sieve )
	
else:
	print >>sys.stderr, "Data source %s not recognized. Check the valid options in the help message."
	sys.exit(-1)

# Seeking
seekevent = None
if( options.gps_start is not None and options.gps_end is not None ):

	# TODO: Use LIGOTimeGPS
	print "Duration: " + str(duration)
	seek, dur = long(start*1e9), long(duration*1e9)
	print >>sys.stderr, "Seeking to GPS %d (ns), segment duration %d (ns)" % (seek, dur)
	print >>sys.stderr, "Will stop at GPS %d (ns)" % (seek + dur)
	seekevent = gst.event_new_seek( 1.0, 
		gst.Format(gst.FORMAT_TIME),
		gst.SEEK_FLAG_KEY_UNIT | gst.SEEK_FLAG_FLUSH,
		gst.SEEK_TYPE_SET, seek,
		gst.SEEK_TYPE_SET, seek + dur
	)

elif( options.gps_start is not None ):

	print >>sys.stderr, "Seeking to GPS %d (ns)" % seek
	seek = long(options.gps_start*1e9)
	seekevent = gst.event_new_seek( 1.0, 
		gst.Format(gst.FORMAT_TIME),
		gst.SEEK_FLAG_KEY_UNIT | gst.SEEK_FLAG_FLUSH,
		gst.SEEK_TYPE_SET, seek,
		gst.SEEK_TYPE_NONE, 0
	)

if( seekevent is not None ):
	if( head.set_state(gst.STATE_READY) != gst.STATE_CHANGE_SUCCESS ):
		exit("Unable to ready pipeline to accept seek.")
	if( not head.send_event( seekevent ) ):
		exit("Unable to send seek event to " + str(head))

# Diagnostic plot
if( diagnostics ):
	head = postdatatee = mktee( pipeline, head )
	mknxydumpsink( pipeline, 
		mkqueue( pipeline, postdatatee ), 
		cfg.get( "diagnostics", "strain-data-output" )
	)

# Convert to 64 bit
head = mkcapsfilter( pipeline, mkaudioconvert( pipeline, head), "audio/x-raw-float,width=64" )
# Data conditioning
head = mkcapsfilter( pipeline, mkresample( pipeline, head ), "audio/x-raw-float,rate=%d" % handler.rate )

if( unicorns ):
	# TODO: Link to lalsim to get the unicorn
	inj_head = gst.element_factory_make( "filesrc" )
	pipeline.add( inj_head )
	inj_head.set_property( "location" , "/Users/chrispankow/work/codedev/excesspower/pipeline/jolien/unicorn1_delay.mp3" )
	inj_head = mkgeneric( pipeline, inj_head, "mad" )
	inj_head = mkaudioconvert( pipeline, inj_head )
	inj_head = mkresample( pipeline, inj_head ) 
	inj_head = mkcapsfilter( pipeline, inj_head, "audio/x-raw-float,channels=1,width=64,rate=%d" % sample_rate )
	inj_head = mkgeneric( pipeline, inj_head, "audioamplify" )
	inj_head.set_property( "amplification", unicorn_volume )
	adder = mkgeneric( pipeline, inj_head, "lal_adder" )
	adder.set_property( "sync", True )
	head.link( adder )
	head = adder

if( inj_loc ):
	head = mkinjections( pipeline, head, inj_loc )

if( inj_loc and verbose ):
	head = mkprogressreport( pipeline, head, "injection stream" )

head = whitener = mkwhiten( pipeline, head )
head = mkqueue( pipeline, head )

# Diagnostic plot
if( diagnostics ):
	head = postresamptee = mktee( pipeline, head )
	mknxydumpsink( pipeline, 
		mkqueue( pipeline, head ), 
		cfg.get( "diagnostics", "whitened-data-output" )
	)

if( verbose ):
	head = mkprogressreport( pipeline, head, "whitened stream" )

# excess power channel firbank
# NOTE: This is where the inspiral pipeline will feed in?
head = mkfirbank( pipeline, head, time_domain=False, block_stride=handler.rate )

# TODO: Make this less hardcodish
# This needs to be done since what is returned by mkfirbank is actually a link to the nofakedisconts element, so the fir bank is hidden
handler.add_firbank( pipeline.get_by_name( "gstlalfirbank0" ) )
nchannels = handler.filter_bank.shape[0]
print "FIR bank constructed with %d %f Hz channels" % (nchannels, base_band)

# TODO: We could limit the number of resolutions available and add an
# audioundersampler here to reduce our workload, for each factor of
# undersampling, we reduce our largest available frequency tile by a factor of 
# 2.
if( verbose ):
	head = mkprogressreport( pipeline, head, "FIR bank stream" )

# TODO: Uncomment here
#head = postfirtee = mkqueue( pipeline, mktee( pipeline, head ) )
#####

if( diagnostics ):
	mknxydumpsink( pipeline, 
		postfirtee, 
		cfg.get( "diagnostics", "fir-output" )
	)

# First branch -- send fully sampled data to wider channels for processing
nlevels = int(numpy.ceil( numpy.log2( nchannels ) )) 
for res_level in range(0, min(handler.max_level, nlevels)):
	# TODO: Uncomment here
	#head = postfirtee
	#######

	head = mkgeneric( pipeline, head, "lal_audioundersample" )

	band = base_band * 2**res_level
	# TODO: Check this
	chan = numpy.ceil( nchannels / 2.0**res_level )

	# The undersample_rate for band = R/2 is => sample_rate (passthrough)
	undersamp_rate = 2 * band
	head = mkcapsfilter( pipeline, head, "audio/x-raw-float,rate=%d" % undersamp_rate )

	if( diagnostics ):
		head = postustee = mktee( pipeline, mkqueue( pipeline, head ) )
		mknxydumpsink( pipeline, postustee, "postundersamp_res_%d.txt" % res_level )

	if( verbose ):
		head = mkprogressreport( pipeline, head, 
			"Undersampled stream level %d" % res_level
		)

	head = matmixer = mkmatrixmixer( pipeline, head )
	handler.add_matmixer( matmixer, res_level )

	head = mkprogressreport( pipeline, head, "post matrix mixer %d" % res_level )

	if( diagnostics ):
		head = postmmtee = mktee( pipeline, mkqueue( pipeline, head ) )
		mknxydumpsink( pipeline, postmmtee, "postmatmix_res_%d.txt" % res_level )

	head = mkgeneric( pipeline, head, "pow" )
	head.set_property( "exponent", 2 )

	if( verbose ):
		head = mkprogressreport( pipeline, head, 
			"Energy stream level %d" % res_level
		)

	# TODO: Uncomment here
	#head = mkqueue( pipeline, head )
	#####

	ndof = 2 # samples -- min number
	# Second branch -- duration
	# max_samp = int(handler.max_duration*rate)
	#while duration <= max_samp:
		#duration = duration << 1

	# Multi channel FIR filter -- used to add together frequency bands into tiles
	# TODO: Restore this when buffer dropping is fixed
	"""
	head = mkgeneric( pipeline, head, "audiofirfilter" )
	head.set_property( "kernel", 
		ep.build_fir_sq_adder( ndof )
	)
	"""

	if( diagnostics ):
		head = postdurtee = mktee( pipeline, mkqueue( pipeline, head ) )
		mknxydumpsink( pipeline, postdurtee, "postdur_res_%d_%d.txt" % (res_level, ndof) )

	if( verbose ):
		head = mkprogressreport( pipeline, head, 
			"After energy summation resolution level %d, %d DOF" % 
				(res_level, ndof) 
		)

	# Reenable for amplitude SNR stream
	#head = mkgeneric( pipeline, head, "pow" )
	#head.set_property( "exponent", 0.5 )

	# TODO: Audio
	if( options.stream_tfmap ):
		if len(options.stream_tfmap.split("=")) == 2:
			split_opt, filename = options.stream_tfmap.split("=")
		else:
			filename = options.stream_tfmap
			# TODO: Make this more elegant
			if( filename == "video" ): filename = None
			split_opt = None

		head = stream_tfmap_video( pipeline, head, 
			handler, 
			filename,
			split_opt
		)

	# Trigger generator
	head = mkbursttriggergen( pipeline, head, ndof, 
		bank = handler.build_filter_xml( res_level )
	)

	if( handler.fap is not None ):
		# Still needs magic number... or use the EP version
		snr_thresh = ep_utils.determine_thresh_from_fap(fap, ndof)
	else:
		snr_thresh = handler.snr_thresh**2
	head.set_property( "snr-thresh", snr_thresh )

	if( verbose ):
		head = mkprogressreport( pipeline, head, 
			"Trigger generator resolution level %d, %d DOF" % 
				(res_level, ndof) 
		)

	# TODO: combine trigger streams from various levels

	# TODO: This will have to be linked to multiple outgoing streams
	appsink = mkappsink(pipeline, mkqueue(pipeline, head))
	appsink.connect_after("new-buffer", get_triggers, handler, ndof)

### END OF PIPELINE

# Spectrum notification processing
whitener.connect_after( "notify::mean-psd", on_psd_change, handler )
# Handle spectral correlation changes
# TODO: Make sure this doesn't have to be in the mm loop
whitener.connect_after( "notify::spectral-correlation", on_spec_corr_change, handler )

# Experimental real time command line handling
signal.signal( signal.SIGUSR1, handler.cmd_line )
# Handle shutdowns
signal.signal( signal.SIGINT, handler.shutdown )
signal.signal( signal.SIGTERM, handler.shutdown )

print >>sys.stderr, "Startin' up."
pipeline.set_state( gst.STATE_PLAYING )
if( diagnostics ):
	write_dump_dot(pipeline, "test", verbose = True)
	#gst.DEBUG_BIN_TO_DOT_FILE( pipeline,
		#gst.DEBUG_GRAPH_SHOW_ALL,
		#cfg.get( "diagnostics", "dot-file-location" )
	#)
mainloop.run()

