#!/usr/bin/python

import gviz_api
import h5py
import os,sys
import cgi
import cgitb
cgitb.enable()
form = cgi.parse()
import numpy
import re
import time
import zlib
#import pyparsing

print "Content-type: application/json"
print "Cache-Control: max-age=10"
print


def now():
	#FIXME use pylal when available
	return time.time() - 315964785

# we have to get a query according to the google standard
assert "tq" in form
assert "tqx" in form
reqId = form["tqx"][0].split(":")[1]
query = form["tq"][0]

# Figure out if a GPS time is being specified, else assume "now"
if "gpstime" in query:
	regex = re.compile("[0-9]{10}")
	query_time = int(regex.search(query).group(0))
else:
	query_time = int(now())

# see if there are additional flags 
# FIXME these are not google API complient.
if "duration" in form:
	duration = int(form["duration"][0])
else:
	duration = 1000

if "type" in form:
	datatype = form["type"]
else:
	datatype = "median"

# FIXME, this is sort of dumb. But I did it this way so that we could tailor it to our needs
if duration <= 10000:# hour
	level = 6
if 10000 < duration <= 100000:
	level = 5
if 100000 < duration <= 1000000:
	level = 4
if 1000000 < duration <= 10000000:
	level = 3
if duration > 10000000:
	level = 2

# a unique identifier for this particular query
# hashnumber = zlib.adler32("".join(sys.argv[1:])+query_time)

thisgpsdir = ""
prevgpsdir = ""
prev_time = query_time - 10**(10-level)
for digit in str(query_time)[0:level]:
	thisgpsdir += "/%s" % digit
for digit in str(prev_time)[0:level]:
	prevgpsdir += "/%s" % digit


# FIXME don't hard code
base_path = "/home/gstlalcbctest/engineering/10/S6/bns"

#
# "SQL" parser.  FIXME. First, google query langauge isn't really SQL and
# second, if this keeps going we need to switch to a parsing library e.g.,
# pyparsing.  For now this is likely to be a collection of once-offs.
#

#
# Data types
#
for route, label in (("latency_history", "Latency (s)"), 
	   ("snr_history", "SNR")
	  ):
	if route in query:
		#for gpsdir in (prevgpsdir, thisgpsdir):
		path = base_path + "/aggregator" + thisgpsdir

		max_time = []
		if "status by node" in query:
			# FIXME at 10,000 second boundaries this query won't
			# return the latest 25 samples, we need to look back a
			# directory
			out_data = []
			path += "/by_job"
			for job in os.listdir(path):
				fname = "%s/%s/median/%s.hdf5" % (path, job, route)
				f = f = h5py.File(fname, "r")
				this_data = numpy.array(f["data"])
				this_time = numpy.array(f["time"])
				ix = numpy.logical_and(this_time > (query_time-duration), this_time <= query_time)
				this_time = this_time[ix]
				this_data = this_data[ix]
				max_time.append(this_time[-1])
				if len(this_data) > 0:
					mindata = numpy.min(this_data)
					maxdata = numpy.max(this_data)
					meandata = numpy.mean(this_data)
					std = numpy.std(this_data)
					out_data.append([job, mindata, meandata-std/2., meandata+std/2., maxdata])
					f.close()
			description = [
				("job", "string"),
				("%d" % max(max_time), "number"),
				("j", "number"),
				("", "number"),
				("", "number")
				]
			
			data_table = gviz_api.DataTable(description)
			data_table.LoadData(out_data)
			print data_table.ToJSonResponse(order_by = "job", req_id = reqId)
			sys.exit()

		if "where node is all" in query:
			# FIXME at 10,000 second boundaries this query won't
			# return all the relevant samples
			# FIXME decide how many samples to return
			out_data = []
			fname = "%s/median/%s.hdf5" % (path, route)
			f = h5py.File(fname, "r")
			this_data = numpy.array(f["data"])
			this_time = numpy.array(f["time"])
			ix = numpy.logical_and(this_time > (query_time-duration), this_time <= query_time)
			this_time = this_time[ix]
			this_data = this_data[ix]
			# FIXME use numpy operations
			out_data.extend([[t,d] for t,d in zip(this_time, this_data)])
			f.close()
			description = [("time", "number"), ("%d" % this_time[-1], "number")]
			data_table = gviz_api.DataTable(description)
			data_table.LoadData(out_data)
			print data_table.ToJSonResponse(order_by = "time", req_id = reqId)
			sys.exit()

		if "now" in query:
			out_data = []
			fname = "%s/median/%s.hdf5" % (path, route)
			f = h5py.File(fname, "r")
			out_data = [[float(f["data"][-1])]]
			f.close()
			description = [(label, "number")]
			data_table = gviz_api.DataTable(description)
			data_table.LoadData(out_data)
			print data_table.ToJSonResponse(req_id = reqId)
			sys.exit()

# there should always be data for this!!
for dt in (("horizon_history", "time", "horizon", "(Mpc)"), ("noise", "time", "noise", "|n(t)|")):
	if dt[0] in query:
		data_type = dt[0]
		out_data = []

		datadict = {}
		latest = {}
		latest["H1"] = 0
		latest["L1"] = 0
		blah = time.time()
		if "now" in query:
			for ifo in ("H1", "L1"):
				datadict[ifo] = {} 
				fname = "%s/dq/%s/%s/median/%s.hdf5" % (base_path, ifo, thisgpsdir, data_type)
				f = h5py.File(fname, "r")
				latest[ifo] = f["time"][-1], f["data"][-1]
				f.close()
			out_data.append([latest["H1"][1], latest["L1"][1]])
			description = [
				("H1 %s" % (dt[3],), "number"),
				("L1 %s" % (dt[3],), "number")
				]
		else:
			for ifo in ("H1", "L1"):
				datadict[ifo] = {} 
				fname = "%s/dq/%s/%s/median/%s.hdf5" % (base_path, ifo, thisgpsdir, data_type)
				f = h5py.File(fname, "r")
				this_time = numpy.array(f["time"])
				this_data = numpy.array(f["data"])
				ix = numpy.logical_and(this_time > (query_time-duration), this_time <= query_time)
				this_time = this_time[ix]
				this_data = this_data[ix]

				for t,d in zip(this_time, this_data):
					datadict[ifo][t] = d
					latest[ifo] = (t,d)
				f.close()
			# FIXME don't harcode
			for t in set(datadict["H1"]) | set(datadict["L1"]):
				out_data.append([t, datadict["H1"].setdefault(t,0), datadict["L1"].setdefault(t,0)])
			description = [
				(dt[1], "number"),
				("H1 %s @ %d" % (dt[3], latest["H1"][0]), "number"),
				("L1 %s @ %d" % (dt[3], latest["L1"][0]), "number")
				]
		
		data_table = gviz_api.DataTable(description)
		data_table.LoadData(out_data)
		print data_table.ToJSonResponse(order_by = "time", req_id = reqId)

# there should always be data for this!!
freq = numpy.array([])
datadict = {}
out_data = []
if "psd" in query:
	for ifo in ("H1", "L1"):
		if "now" in query:
			fname = "%s/dq/%s/%s/psd.hdf5" % (base_path, ifo, thisgpsdir)
		else:
			# PSD files are like: H1-PSD-1159632740-10.hdf5
			fname = "%s/dq/%s/%s/%s-PSD-%d-10.hdf5" % (base_path, ifo, thisgpsdir, ifo, int(round(query_time,-1)))
		f = h5py.File(fname, "r")
		datadict[ifo] = numpy.array(f["asd"])
		# assume same freq vector
		freq = numpy.array(f["freq"])
		f.close()
		print len(datadict[ifo]), len(freq)
	# FIXME don't harcode
	for f, H1asd, L1asd in zip(freq, datadict["H1"], datadict["L1"]):
		out_data.append([f, H1asd, L1asd])
	description = [
		("freq (Hz)", "number"),
		("H1 ASD @ %d" % query_time, "number"),
		("L1 ASD @ %d" % query_time, "number")
		]
	
	data_table = gviz_api.DataTable(description)
	data_table.LoadData(out_data)
	print data_table.ToJSonResponse(order_by = "freq", req_id = reqId)
