#!/usr/bin/python

import gviz_api
import h5py
import os
import cgi
import cgitb
cgitb.enable()
form = cgi.parse()
import numpy
from gstlal import llweb
#import pyparsing

print "Content-type: application/json"
print

# we have to get a query according to the google standard
# queries must be of the form
# tq = 

assert "tq" in form
assert "reqId" in form
reqId = form["reqId"][0]
query = form["tq"][0]

#
# Default values
#

base_path = "/home/gstlalcbctest/engineering/10/S6/bns"

#
# "SQL" parser.  FIXME. First, google query langauge isn't really SQL and
# second, if this keeps going we need to switch to a parsing library e.g.,
# pyparsing.  For now this is likely to be a collection of once-offs.
#

#
# Data types
#
for dt in (	("latency_history", "Latency"), 
		("snr_history", "SNR")
	):
	if dt[0] in query:
		data_type = dt[0]
		latest_time_path = base_path + "/aggregator"
		# FIXME DONT HARD CODE
		for level in str(int(llweb.now()))[0:6]:
			latest_time_path += "/%s" % level
		out_data = []
		path = latest_time_path
		path += "/by_job"
		for job in os.listdir(path):
			fname = "%s/%s/median/%s.hdf5" % (path, job, data_type)
			f = f = h5py.File(fname, "r")
			this_data = numpy.array(f["data"])[-25:]
			if len(this_data) > 0:
				mindata = numpy.min(this_data)# + numpy.random.randn()
				maxdata = numpy.max(this_data)# + numpy.random.randn()
				meandata = numpy.mean(this_data)
				std = numpy.std(this_data)
				out_data.append([job, mindata, meandata-std/2., meandata+std/2., maxdata])
				f.close()
		description = [
			("job", "string"),
			("std dev", "number"),
			("job median-std/2", "number"),
			("job median+std/2", "number"),
			("job max", "number")
			]
		
		data_table = gviz_api.DataTable(description)
		data_table.LoadData(out_data)
		print data_table.ToJSonResponse(order_by = "job", req_id = reqId)

for dt in (("horizon_history", "time", "horizon"), ("noise", "time", "noise"), ("psd", "freq", "asd")):
	if dt[0] in query:
		data_type = dt[0]
		latest_time_path = base_path + "/dq"
		out_data = []
		path = latest_time_path

		datadict = {}
		latest = {}
		latest["H1"] = 0
		latest["L1"] = 0
		for ifo in ("H1", "L1"):
			datadict[ifo] = {} 
			try:
				fname = "%s/%s/%s.hdf5" % (path, ifo, data_type)
				f = f = h5py.File(fname, "r")
				for t,d in zip(f[dt[1]], f[dt[2]]):
					datadict[ifo][t] = d
					latest[ifo] = (t,d)
				f.close()
			except IOError:
				pass

		if "now" in query:
			out_data.append([latest["H1"][1], latest["L1"][1]])
			description = [
				("H1 %s" % (dt[2],), "number"),
				("L1 %s" % (dt[2],), "number")
				]
		else:
			# FIXME don't harcode
			for t in set(datadict["H1"]) | set(datadict["L1"]):
				out_data.append([t, datadict["H1"].setdefault(t,0), datadict["L1"].setdefault(t,0)])
			description = [
				(dt[1], "number"),
				("H1 %s" % dt[2], "number"),
				("L1 %s" % dt[2], "number")
				]
		
		data_table = gviz_api.DataTable(description)
		data_table.LoadData(out_data)
		print data_table.ToJSonResponse(order_by = "time", req_id = reqId)
