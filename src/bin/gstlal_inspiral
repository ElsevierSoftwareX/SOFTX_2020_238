#!/usr/bin/env python
#
# Copyright (C) 2010  Kipp Cannon, Chad Hanna
# Copyright (C) 2009  Kipp Cannon, Chad Hanna
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.


#
# =============================================================================
#
#                                   Preamble
#
# =============================================================================
#


import pygtk
pygtk.require('2.0')
import pygst
pygst.require('0.10')
from gstlal.option import OptionParser

import sys
import os.path
import os
import warnings

from glue import segments
from glue import segmentsUtils
from pylal.datatypes import LIGOTimeGPS
from gstlal import ligolw_output



#
# =============================================================================
#
#                                 Command Line
#
# =============================================================================
#




def parse_command_line():
	parser = OptionParser(
		version = "%prog ??",
		usage = "%prog [options]",
		description = "Stream-based inspiral analysis tool"
	)
	parser.add_option("--frame-cache", metavar = "filename", help = "Set the name of the LAL cache listing the LIGO-Virgo .gwf frame files (optional).  This is required unless --fake-data or --online-data is used in which case it must not be set.")
	parser.add_option("--online-data", action = "store_true", help = "Use online DMT-STRAIN instead of a frame file (optional).")
	parser.add_option("--fake-data", action = "store_true", help = "Instead of reading data from .gwf files, generate and process coloured Gaussian noise modelling the Initial LIGO design spectrum (optional).")
	parser.add_option("--gps-start-time", metavar = "seconds", help = "Set the start time of the segment to analyze in GPS seconds (required).  Can be specified to nanosecond precision.")
	parser.add_option("--gps-end-time", metavar = "seconds", help = "Set the end time of the segment to analyze in GPS seconds (required).  Can be specified to nanosecond precision.")
	parser.add_option("--injections", metavar = "filename", help = "Set the name of the LIGO light-weight XML file from which to load injections (optional).")
	parser.add_option("--instrument", metavar = "name", help = "Set the name of the instrument to analyze, e.g. \"H1\" (required).")
	parser.add_option("--channel-name", metavar = "name", default = "LSC-STRAIN", help = "Set the name of the channel to process (optional).  The default is \"LSC-STRAIN\".")
	parser.add_option("--flow", metavar = "Hz", type = "float", default = 40.0, help = "Set the template low-frequency cut-off (default = 40.0).")
	parser.add_option("--svd-tolerance", metavar = "match", type = "float", default = 0.9995, help = "Set the SVD reconstruction tolerance (default = 0.9995).")
	parser.add_option("--nxydump-segment", metavar = "start:stop", default = ":", help = "Set the time interval to dump from nxydump elments (optional).  The default is \":\", i.e. dump all time.")
	parser.add_option("--output", metavar = "filename", help = "Set the name of the LIGO light-weight XML output file *.{xml,xml.gz} or an SQLite database *.sqlite (required).")
	parser.add_option("--reference-psd", metavar = "filename", help = "Instead of measuring the noise spectrum, load the spectrum from this LIGO light-weight XML file (optional).")
	parser.add_option("--template-bank", metavar = "filename", action = "append", help = "Set the name of the LIGO light-weight XML file from which to load the template bank (required).  This option can be given multiple times to process multiple template banks in parallel.")
	parser.add_option("--ortho-gate-fap", metavar = "probability", type = "float", default = 1e-2, help = "Set the orthogonal SNR projection gate false-alarm probability (default = 1e-2).")
	parser.add_option("--snr-threshold", metavar = "SNR", type = "float", default = 5.5, help = "Set the SNR threshold (default = 5.5).")
	parser.add_option("--write-pipeline", metavar = "filename", help = "Write a DOT graph description of the as-built pipeline to this file (optional).  The environment variable GST_DEBUG_DUMP_DOT_DIR must be set for this option to work.")
	parser.add_option("--write-psd", metavar = "filename", help = "Write measured noise spectrum to this LIGO light-weight XML file (optional).  This option has no effect if --reference-psd is used.")
	parser.add_option("--comment", help = "Set the string to be recorded in comment and tag columns in various places in the output file (optional).")
	parser.add_option("-v", "--verbose", action = "store_true", help = "Be verbose (optional).")
	parser.add_option("-t", "--tmp-space", metavar = "path", help = "Path to a directory suitable for use as a work area while manipulating the database file.  The database file will be worked on in this directory, and then moved to the final location when complete.  This option is intended to improve performance when running in a networked environment, where there might be a local disk with higher bandwidth than is available to the filesystem on which the final output will reside.")

	# FIXME: This will only raise an exception if we have pygobject < 2.16.
	# Can we bumpy our pygobject dependency version to 2.16?
	try:
		import gstoption
		parser.add_option_group(gstoption.get_group())
	except:
		warnings.warn("Failed to get GStreamer's option group, not adding command line options for it")

	options, filenames = parser.parse_args()

	if sum(1 for option in ('frame_cache', 'fake_data', 'online_data') if getattr(options, option) is not None) != 1:
		raise ValueError, "must provide exactly one of --frame-cache, --fake-data, --online-data"

	required_options = ["instrument", "output", "template_bank"]

	if options.frame_cache:
		required_options += ["channel_name", "gps_start_time", "gps_end_time"]

	if options.online_data:
		required_options += ["reference_psd"]

	# FIXME: should also check for read permissions
	for bankname in options.template_bank:
		if not os.path.exists(bankname):
			raise SystemExit, "Template bank file %s does not exist." % bankname

	missing_options = [option for option in required_options if getattr(options, option) is None]
	if missing_options:
		raise ValueError, "missing required option(s) %s" % ", ".join("--%s" % option.replace("_", "-") for option in sorted(missing_options))

	# do this before converting option types
	process_params = ligolw_output.make_process_params(options)

	# If --gps-start-time is not specified, assume "beginning of time"
	if options.gps_start_time is None:
		effective_gps_start_time = LIGOTimeGPS(0) # FIXME: should be gobject.G_MININT, but somewhere along the line we have an integer overflow error
	else:
		effective_gps_start_time = LIGOTimeGPS(options.gps_start_time)

	# If --gps-end-time is not specified, assume "end of time"
	if options.gps_end_time is None:
		effective_gps_end_time = LIGOTimeGPS(999999999) # FIXME: should be gobject.G_MAXINT, but somewhere along the line we have an integer overflow error
	else:
		effective_gps_end_time = LIGOTimeGPS(options.gps_end_time)

	options.seg = segments.segment(effective_gps_start_time, effective_gps_end_time)
	options.nxydump_segment, = segmentsUtils.from_range_strings([options.nxydump_segment], boundtype = LIGOTimeGPS)

	options.psd_fft_length = 8	# seconds

	return options, filenames, process_params


#
# =============================================================================
#
#                                     Main
#
# =============================================================================
#


#
# parse command line
#


options, filenames, process_params = parse_command_line()


#
# Import everything that depends on GStreamer
#


from gstlal.pipeutil import *
from gstlal.lloidparts import *
from gstlal import templates
from gstlal.gstlal_svd_bank import build_bank
from gstlal.gstlal_reference_psd import *


#
# construct pipeline metadata and measure the PSD
#


if options.gps_start_time is None:
	seek_start_type = gst.SEEK_TYPE_NONE
	seek_start_time = -1 # gst.CLOCK_TIME_NONE is exported as unsigned, should have been signed
else:
	seek_start_type = gst.SEEK_TYPE_SET
	seek_start_time = options.seg[0].ns()

if options.gps_end_time is None:
	seek_stop_type = gst.SEEK_TYPE_NONE
	seek_stop_time = -1 # gst.CLOCK_TIME_NONE is exported as unsigned, should have been signed
else:
	seek_stop_type = gst.SEEK_TYPE_SET
	seek_stop_time = options.seg[1].ns()

seekevent = gst.event_new_seek(1.0, gst.Format(gst.FORMAT_TIME),
	gst.SEEK_FLAG_FLUSH | gst.SEEK_FLAG_KEY_UNIT,
	seek_start_type, seek_start_time,
	seek_stop_type, seek_stop_time)


detectors = {
	options.instrument: DetectorData(options.frame_cache, options.channel_name)
}


if options.reference_psd is not None:
	psd = read_psd(options.reference_psd, verbose = options.verbose)
else:
	psd = measure_psd(
		options.instrument,
		seekevent,
		detectors[options.instrument],
		options.seg,
		2 * 2048,	# Hz;  must not be less than highest bank fragment sample rate (see below)
		psd_fft_length = options.psd_fft_length,
		fake_data = options.fake_data,
		online_data = options.online_data,
		injection_filename = options.injections,
		verbose = options.verbose
	)
	if options.write_psd is not None:
		write_psd(options.write_psd, psd, verbose = options.verbose)

#
# Make template banks
#

banks = [
	build_bank(filename, psd, options.flow, options.ortho_gate_fap, options.snr_threshold, options.svd_tolerance, verbose = options.verbose)
	for filename in options.template_bank
]
for n, bank in enumerate(banks):
	bank.logname = "bank%d" % n



#
# build pipeline
#


# If we are using online data, then use a running PSD estimate.
# FIXME: this is a hacky way to set it.  We should give the user direct
# control over this setting.
if options.online_data:
	psd = None


#
# Write the pipeline to a dot file.
# This option needs the environment variable GST_DEBUG_DUMP_DOT_DIR
# to be set. There are several choices for the "details"
# (second argument). DEBUG_GRAPH_SHOW_ALL is the most verbose.
#
def maybe_dump_dot(pipeline, stage):
	if options.write_pipeline is not None:
		filestem = '%s.%s' % (options.write_pipeline, stage)
		filename = '%s.dot' % filestem
		if "GST_DEBUG_DUMP_DOT_DIR" in os.environ.keys():
			gst.DEBUG_BIN_TO_DOT_FILE( pipeline, gst.DEBUG_GRAPH_SHOW_ALL, filestem)
			print >> sys.stderr, "Wrote pipeline to", os.path.join(os.environ["GST_DEBUG_DUMP_DOT_DIR"], filename)
		else:
			print >> sys.stderr, "***Could not write pipeline, please set GST_DEBUG_DUMP_DOT_DIR in your environment"


pipeline = gst.Pipeline("gstlal_inspiral")
mainloop = gobject.MainLoop()
handler = LLOIDHandler(mainloop, pipeline)

src = mkLLOIDmulti(
	pipeline,
	seekevent,
	detectors = detectors,
	banks = banks,
	psd = psd,
	psd_fft_length = options.psd_fft_length,
	fake_data = options.fake_data,
	online_data = options.online_data,
	injection_filename = options.injections,
	verbose = options.verbose,
	nxydump_segment = options.nxydump_segment
)

#
# build output document
#

options.out_seg = segments.segment(options.seg[0]+max([b.filter_length for b in banks]), options.seg[1]) #FIXME make better outseg def.
data = ligolw_output.Data(detectors, process_params, options)
data.prepare_output_file()
mkelems_fast(pipeline, src, "appsink", {"caps": gst.Caps("application/x-lal-snglinspiral"), "sync": False, "async": False, "emit-signals": True, "max-buffers": 1, "drop": True})[-1].connect_after("new-buffer", appsink_new_buffer, data)



#
# process requested segment
#


maybe_dump_dot(pipeline, "NULL")
pipeline.set_state(gst.STATE_PLAYING)
maybe_dump_dot(pipeline, "PLAYING")
mainloop.run()


#
# write output file
#


data.write_output_file()

#
# done
#
