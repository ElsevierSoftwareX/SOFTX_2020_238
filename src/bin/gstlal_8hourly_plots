#!/usr/bin/env python
# Copyright (C) 2010  Erin Kara
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
#

try:
        import sqlite3
except ImportError:
        # pre 2.5.x
        from pysqlite2 import dbapi2 as sqlite3

from optparse import OptionParser
from glue import segments
from glue.ligolw import dbtables
from pylal import git_version

import subprocess
import matplotlib
from matplotlib import colors
from matplotlib import cm
matplotlib.use('Agg')
import pylab
import glob

__author__ = "Erin Kara <ekara@ligo.caltech.edu>"
__version__ = "git id %s" % git_version.id
__date__ = git_version.date

##############################################################
# Main Code
##############################################################


def parse_command_line():
	parser = OptionParser(version = "%prog CVS $Id$", usage = "%prog [options] [file ...]", description = "%prog computes mass/mass upperlimit")
	parser.add_option("-t", "--tmp-space", metavar = "path", help = "Path to a directory suitable for use as a work area while manipulating the database file.  The database file will be worked on in this directory, and then moved to the final location when complete.  This option is intended to improve performance when running in a networked environment, where there might be a local disk with higher bandwidth than is available to the filesystem on which the final output will reside.")
	parser.add_option("--verbose", action = "store_true", help = "Be verbose.")
	parser.add_option("-f", "--followups", type = int, help = "Specify the number of followups from each detector to run in the followup pipeline.  If None then no followups are done.")
	parser.add_option("--glob", help="bash glob pattern")
	
	opts, filenames = parser.parse_args()
	if opts.glob: filenames.extend(glob.glob(opts.glob))

	if not filenames:
		raise RuntimeError("must specify at least one database file")
	return opts, filenames


opts,databases = parse_command_line()


import os
from glue.segmentdb import query_engine
from glue.segmentdb import segmentdb_utils
connection = segmentdb_utils.setup_database(os.getenv('S6_SEGMENT_SERVER'))
engine = query_engine.LdbdQueryEngine(connection)


def get_science_segments(ifo, start_time, end_time):
	segdefs = segmentdb_utils.expand_version_number(engine, (ifo, 'DMT-SCIENCE', 1, start_time, end_time, 0, 0) )
	return segmentdb_utils.query_segments(engine, 'segment', segdefs)


def get_hwinj_segments(ifo, start_time, end_time):
	segdefs = segmentdb_utils.expand_version_number(engine, (ifo, 'DMT-INJECTION_INSPIRAL', 1, start_time, end_time, 0, 0) )
	return segmentdb_utils.query_segments(engine, 'segment', segdefs)


args = []
for f in databases:
	# Connect with SQLite
	working_filename = dbtables.get_connection_filename(f, tmp_path=opts.tmp_space, verbose = opts.verbose)
	connection = sqlite3.connect(working_filename)
	dbtables.DBTable_set_connection(connection)


	# Get input start and end time
	in_start_time, in_end_time = connection.execute("SELECT in_start_time, in_end_time FROM search_summary LIMIT 1").fetchone()


	# Select Parameters from sngl_inspiral table
	params = pylab.array(
		connection.cursor().execute("SELECT mass1,mass2,snr,chisq,mchirp,end_time+end_time_ns*1.0e-9 as end_time,eff_distance FROM sngl_inspiral").fetchall(),
		dtype=[(field_name,float) for field_name in "mass1,mass2,snr,chisq,mchirp,end_time,eff_distance".split(',')]
	)
	ifo = f.strip("gstlal_inspiral..sqlite")

	# Look up science segments
	science_segments = get_science_segments(ifo, in_start_time, in_end_time)[0]
	non_science_segments = segments.segmentlist([segments.segment(in_start_time, in_end_time)]) - science_segments

	# Look up hwinj segments
	hwinj_segments = get_hwinj_segments(ifo, in_start_time, in_end_time)[0]

	# Plot m1 vs m2
	pylab.clf()
	plot=pylab.scatter(params['mass1'], params['mass2'], c=params['snr'], edgecolor=None)
	pylab.colorbar().set_label("SNR")
	pylab.xlabel("mass1")
	pylab.ylabel("mass2")
	pylab.title("mass1 vs. mass2 for %s" % ifo)
	pylab.grid(True)
	pylab.savefig("m1_m2_%s" % ifo)


	# Plot SNR vs ChiSq
	pylab.clf()
	pylab.xscale('log')
	pylab.yscale('log')
	pylab.scatter(params['snr'], params['chisq'], c=params['mchirp'], edgecolor=None)
	pylab.axis("tight")
	pylab.colorbar(plot).set_label("mchirp")
	pylab.xlabel("SNR")
	pylab.ylabel("ChiSq")
	pylab.title("SNR vs. ChiSq for %s" %ifo)
	pylab.grid(True)
	pylab.savefig("snr_chisq_%s" %ifo)


	# Plot SNR vs end_time
	pylab.clf()
	pylab.semilogy(params['end_time'], params['snr'], 'or')
	for seg in non_science_segments:
		pylab.axvspan(seg[0], seg[1], facecolor='0.75')
	for seg in hwinj_segments:
		pylab.axvspan(seg[0], seg[1], facecolor='blue', edgecolor='none')
	pylab.axis("tight")
	pylab.xlabel("end_time")
	pylab.ylabel("SNR")
	pylab.title("SNR vs end_time for %s" %ifo)
	pylab.grid(True)
	pylab.savefig("snr_endtime_%s" %ifo)


	# Plot net trigger rate
	pylab.clf()
	pylab.yscale('log')
	pylab.hist(params['end_time'], bins=pylab.arange(in_start_time, in_end_time, 60), histtype='bar', color='r')
	for seg in non_science_segments:
		pylab.axvspan(seg[0], seg[1], facecolor='0.75')
	pylab.axis("tight")
	pylab.ylim(0.1, 1.0e5)
	pylab.xlabel("end_time")
	pylab.ylabel("Triggers/minute")
	pylab.title("Net trigger rate vs end_time for %s" %ifo)
	pylab.grid(True)
	pylab.savefig("triggerrate_%s" %ifo)


	# Plot SNR vs D_eff
	pylab.clf()
	pylab.loglog(params['snr'], params['eff_distance'], 'or')
	pylab.xlabel("SNR")
	pylab.ylabel("eff_distance")
	pylab.title("eff_distance vs SNR for %s" %ifo)
	pylab.grid(True)
	pylab.savefig("snr_effdistance_%s" %ifo)


	# Select gps times for top ten SNR values from each database
	max_triggers = opts.followups
	if (max_triggers != None):
		top_triggers = connection.cursor().execute("SELECT end_time + (end_time_ns*1e-9) FROM sngl_inspiral ORDER BY snr DESC LIMIT %d" % max_triggers)
		gps_times = [c[0] for c in top_triggers]	
		for row in gps_times:
			args.append("%s:%f" % (ifo, row))

	
	# Close connection to SQLite	
	dbtables.discard_connection_filename(f, working_filename, verbose = opts.verbose)
	dbtables.DBTable_set_connection(None)


# Open subprocess to make create a dag from top 20 triggers
if (max_triggers != None):
	cmd = "lalapps_followup_pipe -g " + ",".join(args)
	process = subprocess.Popen(cmd, shell=True) 

