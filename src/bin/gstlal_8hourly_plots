#!/usr/bin/env python
# Copyright (C) 2010  Erin Kara
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
#

try:
	import sqlite3
except ImportError:
	# pre 2.5.x
	from pysqlite2 import dbapi2 as sqlite3

from optparse import OptionParser
from glue import segments
from glue.ligolw import dbtables

import subprocess
import matplotlib
matplotlib.use('Agg')
import pylab
import glob

__author__ = "Erin Kara <ekara@ligo.caltech.edu>"

##############################################################
# Main Code
##############################################################


def parse_command_line():
	parser = OptionParser(version = "%prog CVS $Id$", usage = "%prog [options] [file ...]", description = "%prog computes mass/mass upperlimit")
	parser.add_option("-t", "--tmp-space", metavar = "path", help = "Path to a directory suitable for use as a work area while manipulating the database file.  The database file will be worked on in this directory, and then moved to the final location when complete.  This option is intended to improve performance when running in a networked environment, where there might be a local disk with higher bandwidth than is available to the filesystem on which the final output will reside.")
	parser.add_option("--verbose", action = "store_true", help = "Be verbose.")
	parser.add_option("-f", "--followups", type = int, help = "Specify the number of followups from each detector to run in the followup pipeline.  If None then no followups are done.")
	parser.add_option("--glob", help="bash glob pattern")
	
	opts, filenames = parser.parse_args()
	if opts.glob: filenames.extend(glob.glob(opts.glob))

	if not filenames:
		raise RuntimeError("must specify at least one database file")
	return opts, filenames


opts,databases = parse_command_line()


args = []
for f in databases:
	# Connect with SQLite
	working_filename = dbtables.get_connection_filename(f, tmp_path=opts.tmp_space, verbose = opts.verbose)
	connection = sqlite3.connect(working_filename)
	dbtables.DBTable_set_connection(connection)


	# Get input start and end time
	in_start_time, in_end_time = connection.execute("SELECT in_start_time, in_end_time FROM search_summary LIMIT 1").fetchone()


	# Select Parameters from sngl_inspiral table
	params = pylab.array(
		connection.cursor().execute("SELECT mass1,mass2,snr,chisq,mchirp,end_time+end_time_ns*1.0e-9 as end_time,eff_distance FROM sngl_inspiral").fetchall(),
		dtype=[(field_name,float) for field_name in "mass1,mass2,snr,chisq,mchirp,end_time,eff_distance".split(',')]
	)
	ifo = f.strip("gstlal_inspiral..sqlite")

	# Look up science segments
	science_segments = segments.segmentlist(connection.cursor().execute("SELECT start_time, end_time FROM segment").fetchall())
	non_science_segments = segments.segmentlist([segments.segment(in_start_time, in_end_time)]) - science_segments

	# Look up hwinj segments
	hwinj_times = pylab.array(connection.cursor().execute("""
		SELECT geocent_end_time + geocent_end_time_ns*1.0e-9 AS geocent_end_time_s
		FROM sim_inspiral INNER JOIN segment
		WHERE geocent_end_time_s BETWEEN start_time AND end_time"""
	).fetchall())


	# Plot SNR vs ChiSq
	pylab.clf()
	if len(params) > 0:
		pylab.hexbin(params['snr'], params['chisq'], xscale='log', yscale='log', bins='log')
		pylab.colorbar().set_label("number of triggers")
		pylab.axis("tight")
	pylab.xlabel("SNR")
	pylab.ylabel("ChiSq")
	pylab.title("SNR vs. ChiSq for %s triggers" %ifo)
	pylab.grid(True)
	pylab.savefig("snr_chisq_%s" %ifo)


	# Plot Effective SNR vs ChiSq
	pylab.clf()
	if len(params) > 0:
		eff_snr = params['snr'] * (params['chisq']/398.0 * (1 + params['snr'] ** 2 / 250.0)) ** -0.25
		pylab.hexbin(eff_snr, params['chisq'], xscale='log', yscale='log', bins='log')
		pylab.colorbar().set_label("number of triggers")
		pylab.axis("tight")
	pylab.xlabel("Effective SNR")
	pylab.ylabel("ChiSq")
	pylab.title("Effective SNR vs. ChiSq for %s triggers" %ifo)
	pylab.grid(True)
	pylab.savefig("eff_snr_chisq_%s" %ifo)


	# Plot SNR vs end_time
	pylab.clf()
	if len(params) > 0:
		pylab.semilogy(params['end_time'], params['snr'], 'or')
	for seg in non_science_segments:
		pylab.axvspan(seg[0], seg[1], facecolor='0.75')
	for t in hwinj_times:
		pylab.axvline(t, color='blue')
	pylab.xlim(in_start_time, in_end_time)
	if len(params) > 0:
		pylab.ylim(params['snr'].min(), params['snr'].max())
	pylab.xlabel("end_time")
	pylab.ylabel("SNR")
	pylab.title("SNR vs end_time for %s" %ifo)
	pylab.grid(True)
	pylab.savefig("snr_endtime_%s" %ifo)


	# Plot Effective SNR vs end_time
	pylab.clf()
	if len(params) > 0:
		pylab.semilogy(params['end_time'], eff_snr, 'or')
	for seg in non_science_segments:
		pylab.axvspan(seg[0], seg[1], facecolor='0.75')
	for t in hwinj_times:
		pylab.axvline(t, color='blue')
	pylab.xlim(in_start_time, in_end_time)
	pylab.ylim(1, 100)
	pylab.xlabel("end_time")
	pylab.ylabel("Effective SNR")
	pylab.title("Effective SNR vs end_time for %s" %ifo)
	pylab.grid(True)
	pylab.savefig("eff_snr_endtime_%s" %ifo)


	# Plot net trigger rate
	pylab.clf()
	pylab.yscale('log')
	if len(params) > 0:
		pylab.hist(params['end_time'], bins=pylab.arange(in_start_time, in_end_time, 60), histtype='bar')
	for seg in non_science_segments:
		pylab.axvspan(seg[0], seg[1], facecolor='0.75')
	pylab.xlim(in_start_time, in_end_time)
	pylab.ylim(0.1, 1.0e5)
	pylab.xlabel("end_time")
	pylab.ylabel("Triggers/minute")
	pylab.title("Net trigger rate vs end_time for %s" %ifo)
	pylab.grid(True)
	pylab.savefig("triggerrate_%s" %ifo)


	# Plot SNR vs D_eff
	pylab.clf()
	if len(params) > 0:
		pylab.loglog(params['snr'], params['eff_distance'], 'or')
	pylab.xlabel("SNR")
	pylab.ylabel("eff_distance")
	pylab.title("eff_distance vs SNR for %s" %ifo)
	pylab.grid(True)
	pylab.savefig("snr_effdistance_%s" %ifo)


	# Select gps times for top ten SNR values from each database
	max_triggers = opts.followups
	if (max_triggers != None):
		top_triggers = connection.cursor().execute("SELECT end_time + (end_time_ns*1e-9) FROM sngl_inspiral ORDER BY snr DESC LIMIT %d" % max_triggers)
		gps_times = [c[0] for c in top_triggers]	
		for row in gps_times:
			args.append("%s:%f" % (ifo, row))

	
	# Close connection to SQLite	
	dbtables.discard_connection_filename(f, working_filename, verbose = opts.verbose)
	dbtables.DBTable_set_connection(None)


# Open subprocess to make create a dag from top 20 triggers
if (max_triggers != None):
	cmd = "lalapps_followup_pipe -g " + ",".join(args)
	process = subprocess.Popen(cmd, shell=True) 

