#!/usr/bin/env python
# Copyright (C) 2010  Erin Kara, Chad Hanna
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
#


from optparse import OptionParser
from glue import cbcwebpage

__author__ = "Erin Kara <ekara@ligo.caltech.edu>"


#######################################################################
# Main Code
#######################################################################


parser = OptionParser(version = "%prog CVS $Id$")
parser.add_option("-f", "--followups", action="store_true", default=False, help="Enable followup pipeline output.  Disabled by default.")
opts,args = parser.parse_args()


if len(args) > 0:
	raise RuntimeError("Did not understand extra command line arguments: %r" % args)



# Make an instance of cbcpage
page = cbcwebpage.cbcpage(title="gstlal 8-hour Job Page")


# Section for Correlations between sngl_inspiral parameters
subpage = page.add_subpage("sngl","Single Detector Overview","Single Detector Overview")


sect = subpage.add_section("perf", "Performance", open_by_default=True)
sect.add_table(cbcwebpage.image_glob("gstlal_inspiral.*.out.png", width=360), "Single Detector Progress")
sect.add_table(cbcwebpage.image_glob("triggerrate_*.png", width=360), "Net Trigger Rate")


sect = subpage.add_section("trig", "Single Detector Trigger Distribution", open_by_default=True)
sect.add_table(cbcwebpage.image_glob("snr_chisq_*.png", width=360), "Chi Squared vs. SNR")
sect.add_table(cbcwebpage.image_glob("eff_snr_chisq_*.png", width=360), "Chi Squared vs. Effective SNR")
sect.add_table(cbcwebpage.image_glob("snr_endtime_*.png", width=360), "SNR vs. End Time")
sect.add_table(cbcwebpage.image_glob("eff_snr_endtime_*.png", width=360), "Effective SNR vs. End Time")
sect.add_table(cbcwebpage.image_glob("snr_effdistance_*.png", width=360), "Effective Distance vs. SNR")



# Parse the cache.
if opts.followups:
	import sys
	from pylal.followup_page import *

	coinc_info, cache = cache_parser("followup_pipe.cache")

	# Loop over different "searches" like full data, etc.
	for search, coincs in coinc_info.items():
		events = []


		# pull out the events and sort them
		for coinc in coincs:
			events.append(Coinc(coinc, search, cache))
		events.sort(key=lambda x: x.rank)


		# loop over the followed up events
		for event in events:
			print >>sys.stderr, "processing coinc@%s in %s" % (event.coinctime, search)
			key = (str(event.coinctime))
			page.add_subpage(key,"my new page",link_text=key)
			#section for param table
			if search.lower() != "gps_only": event.write_param_table(page.subpages[key])
			#section for qscans
			event.add_htqscan(page.subpages[key])
			#section for seismic qscans
			event.add_seismicqscan(page.subpages[key])
			#section for rds qscans (CVT)
			event.add_rdsqscan(page.subpages[key])
			#dq
			event.add_dq(page.subpages[key])


# write the page to disk
page.write()
