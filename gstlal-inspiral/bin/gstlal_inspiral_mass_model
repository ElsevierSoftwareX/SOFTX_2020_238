#!/usr/bin/env python
#
# Copyright (C) 2017,2018  Heather Fong and Chad Hanna
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

import h5py
import argparse
import numpy
from glue.ligolw import ligolw
from glue.ligolw import lsctables, param as ligolw_param, array as ligolw_array
from glue.ligolw import utils as ligolw_utils
from glue.ligolw.utils import process as ligolw_process
import lal.series
from lal import rate
from gstlal import reference_psd

@ligolw_array.use_in
@ligolw_param.use_in
@lsctables.use_in
class LIGOLWContentHandler(ligolw.LIGOLWContentHandler):
	pass

def chirpmass(m1, m2):
	return (m1 * m2)**.6 / (m1 + m2)**.2

def schechter_norm(lower, upper, maxM, alpha):
	norm_masses = numpy.linspace(lower, upper, 10000)
	return numpy.sum(schechter(norm_masses, maxM, alpha)) * (norm_masses[1] - norm_masses[0])

def schechter(mass, maxM, alpha):
	return (mass / maxM)**alpha * numpy.exp(-mass / maxM) / maxM

parser = argparse.ArgumentParser(description = "Create analytic mass models for prior weighting of templates")
parser.add_argument("--template-bank", metavar='name', type=str, help='The input template bank file name.', required = True)
parser.add_argument("--reference-psd", metavar='filename', help = "Load the spectrum from this LIGO light-weight XML file")
parser.add_argument("--output", metavar='name', type=str, help='The output file name', default = "inspiral_mass_model.h5")
parser.add_argument("--model", metavar='name', type=str, help='Mass model. Options are: ligo, narrow-bns, broad-bns, bbh, detected-logm. If you want another one, submit a patch.')
parser.add_argument("--verbose", help='Be verbose', action="store_true")
options = parser.parse_args()

# Read the template bank file
xmldoc = ligolw_utils.load_filename(options.template_bank, verbose = options.verbose, contenthandler = LIGOLWContentHandler)
sngl_inspiral_table = lsctables.SnglInspiralTable.get_table(xmldoc)
if options.model == "detected-logm":
	psd = lal.series.read_psd_xmldoc(ligolw_utils.load_filename(options.reference_psd, verbose = True, contenthandler = lal.series.PSDContentHandler))

mchirps_of_tmps = chirpmass(sngl_inspiral_table.get_column("mass1"), sngl_inspiral_table.get_column("mass2"))

# NOTE this next block of code isn't used since we don't actuall have a  PDF in mass space. Maybe some day?
# num_templates = len(mchirps_of_tmps)
# num_bins = max(5, num_templates / 500)
# massBA = rate.BinnedDensity(rate.NDBins((rate.LogarithmicBins(min(mchirps_of_tmps)-1e-6, max(mchirps_of_tmps)+1e-6, num_bins),)))
# for m in mchirps_of_tmps:
#	massBA.count[(m,)] += 1
# rate.filter_array(massBA.array, rate.gaussian_window(num_bins / 50., sigma = 5))

# Assign the proper mass probabilities
prob = {}
mchirps = {}

ligo_min = 3
ligo_max = 40
ligo_peak = 40
ligo_alpha = -1
ligonorm = schechter_norm(ligo_min, ligo_max, ligo_peak, ligo_alpha)

bbh_min = 3
bbh_max = 30
bbh_peak = 30
bbh_alpha = -1
bbhnorm = schechter_norm(bbh_min, bbh_max, bbh_peak, bbh_alpha)

for row in sngl_inspiral_table:
	assert row.template_id not in prob

	mchirp = chirpmass(row.mass1, row.mass2)
	mchirps[row.template_id] = mchirp

	if options.model == "narrow-bns":
		sigma = 0.04
		mean = 1.20
		prob[row.template_id] = 1. / (2 * numpy.pi * sigma**2)**.5 * numpy.exp(-(mchirp - mean)**2 / 2. / sigma**2)

	elif options.model == "broad-bns":
		sigma = 0.155
		# comes from mean of 1.25444859344 at z = 0.02
		mean = 1.28
		prob[row.template_id] = 1. / (2 * numpy.pi * sigma**2)**.5 * numpy.exp(-(mchirp - mean)**2 / 2. / sigma**2)

	elif options.model == "detected-logm":
		# FIXME should this be **3 or **2?  The term in LR is here: https://git.ligo.org/lscsoft/gstlal/blob/master/gstlal-inspiral/python/stats/inspiral_lr.py#L354
		hdist = reference_psd.HorizonDistance(15, 1024, 1./4., row.mass1, row.mass2, (0., 0., row.spin1z), (0., 0., row.spin2z))(psd["H1"])[0]
		prob[row.template_id] = numpy.log(mchirp) / hdist**3

	elif options.model == "bbh":
		#
		# BBH portion
		#

		# From: https://www.lsc-group.phys.uwm.edu/ligovirgo/cbcnote/RatesAndSignificance/O1O2CatalogRates
		prob[row.template_id] = schechter(mchirp, bbh_peak, bbh_alpha) / bbhnorm 

	elif options.model == "ligo":

		#
		# BNS portion
		#

		# assume a 0.15 solar mass std deviation, this should capture both population distribution and snr effects
		sigma = 0.15
		mean = 1.2
		bnsprob = 1. / (2 * numpy.pi * sigma**2)**.5 * numpy.exp(-(mchirp - mean)**2 / 2. / sigma**2)

		#
		# BBH portion
		#

		bbhprob = schechter(mchirp, ligo_peak, ligo_alpha) / ligonorm

		#
		# Combined
		#

		# make intrinsic BNS rate 10 times higher (it is actually probably 20 times higher)
		bns_rate = 10.
		bbh_rate = 1.
		# FIXME if the noise is ever normalized over mass then we would need the following, but it isn't
		#prob[row.template_id] = (bns_rate * bnsprob + bbh_rate * bbhprob) / massBA[(mchirp,)] / (bns_rate + bbh_rate)
		prob[row.template_id] = (bns_rate * bnsprob + bbh_rate * bbhprob) / (bns_rate + bbh_rate)
	else:
		raise ValueError("Invalid mass model")

ids = sorted(prob.keys())
norm = numpy.sum(prob.values())
chirpmasses = numpy.array([mchirps[tid] for tid in ids])
coefficients = numpy.zeros((1, 1, max(ids)+1), dtype=float)
for tid in ids:
	coefficients[0,0,tid] = numpy.log(prob[tid]) - numpy.log(norm)

#import matplotlib
#matplotlib.use('agg')
#from matplotlib import pyplot
##pyplot.semilogx(chirpmasses, coefficients[0,0,:] + numpy.log((chirpmasses)**(15./6.)), "*")
#pyplot.semilogx(chirpmasses, coefficients[0,0,:], "*")
#pyplot.grid()
#pyplot.ylim([-20, 0])
#pyplot.savefig("blah.png")

# Write it out
f = h5py.File(options.output, "w")
# put in a dummy interval for the piecewise polynomials in SNR
f.create_dataset("SNR", data = numpy.array([0., 100.]))
f.create_dataset("coefficients", data = coefficients, compression="gzip")
f.create_dataset("event_id", data = numpy.array(ids).astype(int))
f.close()
