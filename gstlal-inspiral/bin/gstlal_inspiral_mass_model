#!/usr/bin/env python
#
# Copyright (C) 2017,2018  Heather Fong and Chad Hanna
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

import h5py
import argparse
import numpy
from glue.ligolw import ligolw
from glue.ligolw import lsctables, param as ligolw_param, array as ligolw_array
from glue.ligolw import utils as ligolw_utils
from glue.ligolw.utils import process as ligolw_process
import lal.series
from lal import rate

@ligolw_array.use_in
@ligolw_param.use_in
@lsctables.use_in
class LIGOLWContentHandler(ligolw.LIGOLWContentHandler):
	pass

def chirpmass(m1, m2):
	return (m1 * m2)**.6 / (m1 + m2)**.2

parser = argparse.ArgumentParser(description = "Create analytic mass models for prior weighting of templates")
parser.add_argument("--template-bank", metavar='name', type=str, help='The input template bank file name.', required = True)
parser.add_argument("--output", metavar='name', type=str, help='The output file name', default = "inspiral_mass_model.h5")
parser.add_argument("--model", metavar='name', type=str, help='Mass model. Options are: salpeter, ligo. If you want another one, submit a patch.')
parser.add_argument("--verbose", help='Be verbose', action="store_true")
options = parser.parse_args()

# Read the template bank file
xmldoc = ligolw_utils.load_filename(options.template_bank, verbose = options.verbose, contenthandler = LIGOLWContentHandler)
sngl_inspiral_table = lsctables.SnglInspiralTable.get_table(xmldoc)

#
# Someday if noise is actually a pdf in mass this might matter
#
# mass1 = sngl_inspiral_table.get_column("mass1")
# mass2 = sngl_inspiral_table.get_column("mass2")
# num_templates = len(mass1)
# num_bins = max(2, int((num_templates / 100.)**.5))
# min_mass = min(min(mass1), min(mass2)) - 1.e-6
# max_mass = max(max(mass1), max(mass2)) + 1.e-6
# massBA = rate.BinnedDensity(rate.NDBins((rate.LogarithmicBins(min_mass, max_mass, num_bins), rate.LogarithmicBins(min_mass, max_mass, num_bins))))
# for m1, m2 in zip(mass1, mass2):
# 	massBA.count[(m1, m2)] += 1
# 	massBA.count[(m2, m1)] += 1
# rate.filter_array(massBA.array, rate.gaussian_window(1.5, 1.5, sigma = 5))

# Assign the proper mass probabilities
ids = {}
tmplt_ids = []
for row in sngl_inspiral_table:
	assert row.template_id not in ids
        tmplt_ids.append(int(row.template_id))
	primary = max(row.mass1, row.mass2)
	if options.model == "salpeter":
		ids[row.template_id] = primary**-2.35# / massBA[row.mass1, row.mass2]
	elif options.model == "ligo":
		# assume a 0.15 solar mass std deviation, this should capture both population distribution and snr effects
		sigma = 0.15
		mean = 1.2
		bnsprob = 1. / (2 * numpy.pi * sigma**2)**.5 * numpy.exp(-(chirpmass(row.mass1, row.mass2) - mean)**2 / 2. / sigma**2)
		# normalised over 5 -- 45 Msun
		bbhprob = 0.46 * primary**-1.6
		# From: https://www.lsc-group.phys.uwm.edu/ligovirgo/cbcnote/RatesAndSignificance/O1O2CatalogRates
		bns_to_bbh_rate = 916. / 56.
		ids[row.template_id] = (bns_to_bbh_rate * bnsprob + bbhprob)# / massBA[row.mass1, row.mass2]
	else:
		raise ValueError("Invalid mass model")

norm = sum(ids.values())
coefficients = numpy.zeros((1, 1, max(ids)+1), dtype=float)
for tid in ids:
	coefficients[0,0,tid] = numpy.log(ids[tid] / norm * len(sngl_inspiral_table))

# Write it out
f = h5py.File(options.output, "w")
# put in a dummy interval for the piecewise polynomials in SNR
f.create_dataset("SNR", data = numpy.array([0., 100.]))
f.create_dataset("coefficients", data = coefficients, compression="gzip")
f.create_dataset("event_id", data = numpy.array(tmplt_ids).astype(int))
f.close()
