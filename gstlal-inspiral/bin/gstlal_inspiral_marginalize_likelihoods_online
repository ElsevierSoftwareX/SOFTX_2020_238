#!/bin/bash
#
# Copyright (C) 2012,2014  Kipp Cannon
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

## @file gstlal_inspiral_marginalize_likelihoods_online
#
# This program runs gstlal_inspiral_marginalize_likelihood in a while True
# loop; See gstlal_inspiral_marginalize_likelihoods_online for more details
#
#
# This program is not meant to be executed standalone by a user. It should be
# part of a DAG managing a running gstlal_inspiral online analysis.
#
# This program takes two or more arguments;
#
# - The path of the output file name
# - One or more root URLs of the web servers from which to retrieve event
#   parameter distribution data (e.g., "http://node001.ligo.caltech.edu")
#
# This program queries each running gstlal_inspiral job via the URL,
# computes PDFs of the likelihood ratio ranking statistics from the
# parameter distribution data, then marginalizes the ranking statistic PDFs
# across jobs and writes the result to the given output file.
#
# It continues to do that in an infinite loop with a 10 minute pause on
# each iteration.  Files are not overwritten directly, but rather via a
# temporary file and mv operation to ensure that no files are corrupted in
# a POSIX file environment.
#
# ### Review status
#
# | Names                                       | Hash                                        | Date       |
# | ------------------------------------------- | ------------------------------------------- | ---------- |
# | Florent, Jolien, Kipp, Chad                 | 0e96523b8846e5a4597ba3477c8462443470cd94    | 2015-05-15 |
#
# #### Action
#


#
# get the output file name
#

OUTPUT="${1}"
shift

#
# paths to data objects on each job's web management interface
#

LIKELIHOOD_PATH="likelihood.xml"
ZEROLAG_COUNTS_PATH="zero_lag_ranking_stats.xml"

#
# pause for each iteration (seconds)
#

SLEEP="600"

#
# loop forever
#

BACKGROUND_COUNTS=$(mktemp --suffix .xml.gz)
while true ; do
	echo "... sleeping for ${SLEEP} seconds ..."
	sleep ${SLEEP}

	# collect the current coinc parameter PDF data from each job, and
	# run some iterations of the ranking statistic sampler to generate
	# noise and signal model ranking statistic histograms for each job.
	# NOTE:  the zero-lag ranking statistic histograms in the files
	# generated here are all 0.
	RANKING_PDF_FILES=
	for REG in "$@" ; do
		SERVER=$(cat ${REG}) || break
		RANKING_PDF_FILE=$(mktemp --suffix .xml.gz) || break
		RANKING_PDF_FILES="${RANKING_PDF_FILES} ${RANKING_PDF_FILE}"
		gstlal_inspiral_calc_rank_pdfs --ranking-stat-samples 100000 --verbose --output ${RANKING_PDF_FILE} ${SERVER}${LIKELIHOOD_PATH} || break
	done || break

	# sum the noise and signal model ranking statistic histograms
	# across jobs, and include the sum from the previous iteration to
	# build up statistics over time.
	gstlal_inspiral_marginalize_likelihood --verbose --output ${BACKGROUND_COUNTS} ${BACKGROUND_COUNTS} ${RANKING_PDF_FILES} || break
	rm -vf ${RANKING_PDF_FILES}

	# collect and sum the current observed zero-lag ranking statistic
	# histograms from all jobs and combine with the noise and signal
	# model ranking statistic histograms.  instead of overwriting the
	# target file, write to a separate file then use mv to replace the
	# target file atomically.  NOTE:  the noise and signal model
	# ranking statistic histograms in the zero-lag counts files
	# downloaded from the jobs must be all 0!!!
	ZEROLAG_COUNTS_URLS=
	for REG in "$@" ; do
		SERVER=$(cat ${REG}) || break
		ZEROLAG_COUNTS_URLS="${ZEROLAG_COUNTS_URLS} ${SERVER}${ZEROLAG_COUNTS_PATH}"
	done || break
	gstlal_inspiral_marginalize_likelihood --verbose --output ${OUTPUT}.next.gz ${BACKGROUND_COUNTS} ${ZEROLAG_COUNTS_URLS} || break
	mv -f ${OUTPUT}.next.gz ${OUTPUT} || break
	rm -vf ${ZEROLAG_COUNTS}
done
rm -vf ${BACKGROUND_COUNTS}

#
# if this program ends its an error, always, so condor will restart it
#

exit 1
