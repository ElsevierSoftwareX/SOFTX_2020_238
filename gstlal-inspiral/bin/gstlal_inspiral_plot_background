#!/usr/bin/env python
#
# Copyright (C) 2013 Chad Hanna, Kipp Cannon
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

## @file gstlal_inspiral_plot_background
# A program to plot the likelihood distributions in noise of a gstlal inspiral analysis
#
# ### Command line interface
#
#	+ `--database` [filename]: Retrieve search results from this database (optional).  Can be given multiple times.
#	+ `--database-cache` [filename]: Retrieve search results from all databases in this LAL cache (optional).  See lalapps_path2cache.
#	+ `--max-snr` [value] (float): Plot SNR PDFs up to this value of SNR (default = 200).
#	+ `--max-log-lambda` [value] (float): Plot ranking statistic CDFs, etc., up to this value of the natural logarithm of the likelihood ratio (default = 40).
#	+ `--min-log-lambda` [value] (float): Plot ranking statistic CDFs, etc., down to this value of the natural logarithm of the likelihood ratio (default = -5).
#	+ `--output-dir` [path]: Write output to this directory (default = ".").
#	+ `--output-format` [extension]: Select output format by setting the filename extension (default = ".png").
#	+ `--tmp-space` [path]: Path to a directory suitable for use as a work area while manipulating the database file.  The database file will be worked on in this directory, and then moved to the final location when complete.  This option is intended to improve performance when running in a networked environment, where there might be a local disk with higher bandwidth than is available to the filesystem on which the final output will reside.
#	+ `--add-zerolag-to-background`: Add zerolag events to background before populating coincident parameter PDF histograms.
#	+ `--user-tag` [tag]: Set the adjustable component of the description fields in the output filenames (default = "ALL").
#	+ `--plot-snr-snr-pdfs`: Plot the full cache of snr-snr-pdfs.
#	+ `--verbose`: Be verbose.


#
# =============================================================================
#
#                                   Preamble
#
# =============================================================================
#


import itertools
import math
import matplotlib
matplotlib.rcParams.update({
	"font.size": 10.0,
	"axes.titlesize": 10.0,
	"axes.labelsize": 10.0,
	"xtick.labelsize": 8.0,
	"ytick.labelsize": 8.0,
	"legend.fontsize": 8.0,
	"figure.dpi": 600,
	"savefig.dpi": 600,
	"text.usetex": True
})
from matplotlib import figure
from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas
import numpy
from optparse import OptionParser
import sqlite3
import sys


from glue.ligolw import dbtables
from glue.ligolw import lsctables
from glue import segmentsUtils
from lal.utils import CacheEntry
from lalinspiral import thinca


from gstlal import far
from gstlal import plotfar
from gstlal import inspiral_pipe


class SnrChiColourNorm(matplotlib.colors.Normalize):
	def __call__(self, value, clip = None):
		value, is_scalar = self.process_value(value)
		numpy.clip(value, 1e-200, 1e+200, value)

		self.autoscale_None(value)

		vmin = math.log(self.vmin)
		vmax = math.log(self.vmax)
		xbar = (vmax + vmin) / 2.
		delta = (vmax - vmin) / 2.
		pi_2 = math.pi / 2.

		value = (numpy.arctan((numpy.log(value) - xbar) * pi_2 / delta) + pi_2) / math.pi
		return value[0] if is_scalar else value

	def inverse(self, value):
		vmin = math.log(self.vmin)
		vmax = math.log(self.vmax)
		xbar = (vmax + vmin) / 2.
		delta = (vmax - vmin) / 2.
		pi_2 = math.pi / 2.

		value = numpy.exp(numpy.tan(value * math.pi - pi_2) * delta / pi_2 + xbar)
		numpy.clip(value, 1e-200, 1e+200, value)
		return value

	def _autoscale(self, vmin, vmax):
		vmin = math.log(vmin)
		vmax = math.log(vmax)
		xbar = (vmax + vmin) / 2.
		delta = (vmax - vmin) / 2.
		xbar += 2. * delta / 3.
		delta /= 4.
		vmin = math.exp(xbar - delta)
		vmax = math.exp(xbar + delta)
		return vmin, vmax

	def autoscale(self, A):
		self.vmin, self.vmax = self._autoscale(numpy.ma.min(A), numpy.ma.max(A))

	def autoscale_None(self, A):
		vmin, vmax = self._autoscale(numpy.ma.min(A), numpy.ma.max(A))
		if self.vmin is None:
			self.vmin = vmin
		if self.vmax is None:
			self.vmax = vmax


#
# =============================================================================
#
#                                 Command Line
#
# =============================================================================
#


def parse_command_line():
	parser = OptionParser()
	parser.add_option("-d", "--database", metavar = "filename", action = "append", help = "Retrieve search results from this database (optional).  Can be given multiple times.")
	parser.add_option("-c", "--database-cache", metavar = "filename", help = "Retrieve search results from all databases in this LAL cache (optional).  See lalapps_path2cache.")
	parser.add_option("--max-snr", metavar = "SNR", default = 200., type = "float", help = "Plot SNR PDFs up to this value of SNR (default = 200).")
	parser.add_option("--max-log-lambda", metavar = "value", default = 40., type = "float", help = "Plot ranking statistic CCDFs, etc., up to this value of the natural logarithm of the likelihood ratio (default = 40).")
	parser.add_option("--min-log-lambda", metavar = "value", default = -5., type = "float", help = "Plot ranking statistic CCDFs, etc., down to this value of the natural logarithm of the likelihood ratio (default = -5).")
	parser.add_option("--scatter-log-lambdas", metavar = "[low]:[high][,[low]:[high]...]", help = "Overlay scatter plots of candidate parameter co-ordinates on various PDF plots, limiting the candidates to those whose log likelihood ratios are in the given range (default = don't overlay scatter plot).  Use a range of \":\" to plot all candidates.")
	parser.add_option("--output-dir", metavar = "output-dir", default = ".", help = "Write output to this directory (default = \".\").")
	parser.add_option("--output-format", metavar = "extension", default = ".png", help = "Select output format by setting the filename extension (default = \".png\").")
	parser.add_option("-t", "--tmp-space", metavar = "path", help = "Path to a directory suitable for use as a work area while manipulating the database file.  The database file will be worked on in this directory, and then moved to the final location when complete.  This option is intended to improve performance when running in a networked environment, where there might be a local disk with higher bandwidth than is available to the filesystem on which the final output will reside.")
	parser.add_option("--add-zerolag-to-background", action = "store_true", help = "Add zerolag events to background before populating coincident parameter PDF histograms.")
	parser.add_option("--user-tag", metavar = "user-tag", default = "ALL", help = "Set the adjustable component of the description fields in the output filenames (default = \"ALL\").")
	parser.add_option("--plot-snr-snr-pdfs", action = "store_true", help = "Plot the full cache of snr-snr-pdfs.")
	parser.add_option("-v", "--verbose", action = "store_true", help = "Be verbose.")
	options, filenames = parser.parse_args()

	if options.database_cache is not None:
		if options.database is None:
			options.database = []
		options.database += [CacheEntry(line).path for line in open(options.database_cache)]

	valid_formats = (".png", ".pdf", ".svg")
	if options.output_format not in valid_formats:
		raise ValueError("invalid --output-format \"%s\", allowed are %s" % (options.output_format, ", ".join("\"%s\"" % fmt for fmt in valid_formats)))

	if options.scatter_log_lambdas is not None:
		options.scatter_log_lambdas = segmentsUtils.from_range_strings(options.scatter_log_lambdas.split(","), boundtype = float).coalesce()

	options.user_tag = options.user_tag.upper()

	return options, filenames


#
# =============================================================================
#
#                                    Input
#
# =============================================================================
#


def load_distributions(filenames, verbose = False):
	rankingstat, rankingstatpdf = far.marginalize_pdf_urls(filenames, require_ranking_stat = False, require_ranking_stat_pdf = False, verbose = verbose)
	seg = None
	if rankingstat is not None:
		try:
			seg = rankingstat.segmentlists.extent_all()
		except ValueError:
			pass
		if options.add_zerolag_to_background:
			rankingstat.denominator.lnzerolagdensity = rankingstat.zerolag
		rankingstat.finish()
	if rankingstatpdf is not None:
		seg = rankingstatpdf.segments.extent()
	# the segment is only used to construct T050017-style filenames, so
	# just fake one if there's no livetime information
	return rankingstat, rankingstatpdf, (seg if seg is not None else (0, 0))


def load_search_results(filenames, tmp_path = None, verbose = False):
	timeslide_ln_lr = []
	zerolag_ln_lr = []
	timeslide_sngls = []
	zerolag_sngls = []

	for n, filename in enumerate(filenames, 1):
		if verbose:
			print >>sys.stderr, "%d/%d: %s" % (n, len(filenames), filename)
		working_filename = dbtables.get_connection_filename(filename, tmp_path = tmp_path, verbose = verbose)
		connection = sqlite3.connect(working_filename)

		xmldoc = dbtables.get_xml(connection)
		definer_id = lsctables.CoincDefTable.get_table(xmldoc).get_coinc_def_id(thinca.InspiralCoincDef.search, thinca.InspiralCoincDef.search_coinc_type, create_new = False)

		cursor = connection.cursor()

		# subclass to allow it to carry extra attributes
		class snglsdict(dict):
			__slots__ = ("ln_likelihood_ratio", "fap")

		for coinc_event_id, rows in itertools.groupby(cursor.execute("""
SELECT
	coinc_event_map.coinc_event_id,
	coinc_event.likelihood,
	coinc_inspiral.false_alarm_rate,
	EXISTS (
		SELECT
			*
		FROM
			time_slide
		WHERE
			time_slide.time_slide_id == coinc_event.time_slide_id
			AND time_slide.offset != 0
	),
	sngl_inspiral.ifo,
	sngl_inspiral.snr,
	sngl_inspiral.chisq
FROM
	sngl_inspiral
	JOIN coinc_event_map ON (
		coinc_event_map.table_name == 'sngl_inspiral'
		AND coinc_event_map.event_id == sngl_inspiral.event_id
	)
	JOIN coinc_event ON (
		coinc_event.coinc_event_id == coinc_event_map.coinc_event_id
	)
	JOIN coinc_inspiral ON (
		coinc_inspiral.coinc_event_id == coinc_event.coinc_event_id
	)
WHERE
	coinc_event.coinc_def_id == ?
ORDER BY
	coinc_event_map.coinc_event_id
		""", (definer_id,)), lambda row: row[0]):
			rows = list(rows)
			is_timeslide = rows[0][3]
			# {instrument: (snr, chisq)} dictionary
			sngls = snglsdict((row[4], (row[5], row[6])) for row in rows)
			sngls.ln_likelihood_ratio = rows[0][1]
			sngls.fap = rows[0][2]
			if is_timeslide:
				timeslide_sngls.append(sngls)
			else:
				zerolag_sngls.append(sngls)

		cursor.close()
		connection.close()
		dbtables.discard_connection_filename(filename, working_filename, verbose = verbose)

	timeslide_ln_lr = sorted((sngls.ln_likelihood_ratio, sngls.fap) for sngls in timeslide_sngls)
	zerolag_ln_lr = sorted((sngls.ln_likelihood_ratio, sngls.fap) for sngls in zerolag_sngls)

	return timeslide_ln_lr, zerolag_ln_lr, timeslide_sngls, zerolag_sngls


#
# =============================================================================
#
#                                     Main
#
# =============================================================================
#


#
# command line
#


options, filenames = parse_command_line()


#
# load input
#


rankingstat, rankingstatpdf, seg = load_distributions(filenames, verbose = options.verbose)


if options.database:
	timeslide_ln_lr, zerolag_ln_lr, timeslide_sngls, zerolag_sngls = load_search_results(options.database, tmp_path = options.tmp_space, verbose = options.verbose)
	if options.scatter_log_lambdas is not None:
		sngls = [sngl for sngl in timeslide_sngls + zerolag_sngls if sngl.ln_likelihood_ratio in options.scatter_log_lambdas]
	else:
		sngls = None
else:
	timeslide_ln_lr, zerolag_ln_lr, sngls = None, None, None


#
# plots
#


# SNR and \chi^2
for instrument in rankingstat.instruments:
	for snr_chi_type in ("background_pdf", "injection_pdf", "zero_lag_pdf", "LR"):
		fig = plotfar.plot_snr_chi_pdf(rankingstat, instrument, snr_chi_type, options.max_snr, sngls = sngls)
		if fig is None:
			continue
		plotname = inspiral_pipe.T050017_filename(instrument, "GSTLAL_INSPIRAL_PLOT_BACKGROUND_%s_%s_SNRCHI2" % (options.user_tag, snr_chi_type.upper()), seg, options.output_format, path = options.output_dir)
		if options.verbose:
			print >>sys.stderr, "writing %s" % plotname
		fig.savefig(plotname)


# candidate rates
fig = plotfar.plot_rates(rankingstat)
plotname = inspiral_pipe.T050017_filename("H1L1V1", "GSTLAL_INSPIRAL_PLOT_BACKGROUND_%s_RATES" % options.user_tag, seg, options.output_format, path = options.output_dir)
if options.verbose:
	print >>sys.stderr, "writing %s" % plotname
fig.savefig(plotname)


# SNR PDFs
if options.plot_snr_snr_pdfs:
	for (instruments, horizon_distances) in sorted(rankingstat.numerator.SNRPDF.snr_joint_pdf_cache.keys(), key = lambda (a, horizon_distances): sorted(horizon_distances)):
		# they're stored as a frozen set of quantized key/value
		# pairs, need to unquantize them and get a dictionary back
		horizon_distances = rankingstat.numerator.SNRPDF.quantized_horizon_distances(horizon_distances)
		fig = plotfar.plot_snr_joint_pdf(rankingstat.numerator.SNRPDF, instruments, horizon_distances, rankingstat.min_instruments, options.max_snr, sngls = sngls)
		if fig is not None:
			plotname = inspiral_pipe.T050017_filename(instruments, "GSTLAL_INSPIRAL_PLOT_BACKGROUND_%s_SNR_PDF_%s" % (options.user_tag, "_".join(["%s_%s" % (k, horizon_distances[k]) for k in sorted(horizon_distances)]) ), seg, options.output_format, path = options.output_dir)
			if options.verbose:
				print >>sys.stderr, "writing %s" % plotname
			fig.savefig(plotname)


# ranking statistic PDFs and CCDFs
if rankingstatpdf is not None:
	fapfar = far.FAPFAR(rankingstatpdf.new_with_extinction())

	for Title, which, NAME in (("Noise", "noise", "NOISE"), ("Signal", "signal", "SIGNAL")):
		fig = plotfar.plot_likelihood_ratio_pdf(rankingstatpdf, (options.min_log_lambda, options.max_log_lambda), Title, which = which)
		plotname = inspiral_pipe.T050017_filename("COMBINED", "GSTLAL_INSPIRAL_PLOT_BACKGROUND_%s_%s_LIKELIHOOD_RATIO_PDF" % (options.user_tag, NAME), seg, options.output_format, path = options.output_dir)
		if options.verbose:
			print >>sys.stderr, "writing %s" % plotname
		fig.savefig(plotname)

	if zerolag_ln_lr is not None:
		xhi = max(zerolag_ln_lr + timeslide_ln_lr)[0]
		xhi = 5. * math.ceil(xhi / 5.)
		xhi = max(xhi, options.max_log_lambda)
	else:
		xhi = options.max_log_lambda
	fig = plotfar.plot_likelihood_ratio_ccdf(fapfar, (options.min_log_lambda, xhi), observed_ln_likelihood_ratios = zerolag_ln_lr, is_open_box = True)
	plotname = inspiral_pipe.T050017_filename("COMBINED", "GSTLAL_INSPIRAL_PLOT_BACKGROUND_%s_NOISE_LIKELIHOOD_RATIO_CCDF_openbox" % options.user_tag, seg, options.output_format, path = options.output_dir)
	if options.verbose:
		print >>sys.stderr, "writing %s" % plotname
	fig.savefig(plotname)

	fig = plotfar.plot_likelihood_ratio_ccdf(fapfar, (options.min_log_lambda, xhi), observed_ln_likelihood_ratios = timeslide_ln_lr, is_open_box = False)
	plotname = inspiral_pipe.T050017_filename("COMBINED", "GSTLAL_INSPIRAL_PLOT_BACKGROUND_%s_NOISE_LIKELIHOOD_RATIO_CCDF_closedbox" % options.user_tag, seg, options.output_format, path = options.output_dir)
	if options.verbose:
		print >>sys.stderr, "writing %s" % plotname
	fig.savefig(plotname)
