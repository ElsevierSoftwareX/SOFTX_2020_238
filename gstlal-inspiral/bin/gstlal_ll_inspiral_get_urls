#!/usr/bin/env python
#
# Copyright (C) 2014  Chad Hanna, Kipp Cannon
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

## @file
# This program queries running gstlal inspiral jobs in the low latency analysis and downloads pertinent data, e.g., SNR trigger history, segment files, etc.

#
# ### Review status
#
# | Names                                       | Hash                                        | Date       | Diff to Head of Master      |
# | ------------------------------------------- | ------------------------------------------- | ---------- | --------------------------- |
# | Florent, Jolien, Kipp, Chad                 | 8aad48d2d796642a2925c7d70dd207c06c0e9a70    | 2015-05-14 | <a href="@gstlal_inspiral_cgit_diff/bin/gstlal_ll_inspiral_get_urls?id=HEAD&id2=8aad48d2d796642a2925c7d70dd207c06c0e9a70">gstlal_ll_inspiral_get_urls</a> |
#
# #### Action
# - none

## @package gstlal_ll_inspiral_get_urls

#
# =============================================================================
#
#                                   Preamble
#
# =============================================================================
#


import logging
from optparse import OptionParser
import subprocess
import sys
import threading
import time


from gi.repository import GLib


from gstlal import servicediscovery


#
# =============================================================================
#
#                                 Command Line
#
# =============================================================================
#


def parse_command_line():
	parser = OptionParser(description = __doc__)
	parser.add_option("--dump-period", metavar = "seconds", type = "float", default = 180., help = "Wait this many seconds between dumps of the URLs (default = 180., set to 0 to disable)")
	parser.add_option("--job-tag", metavar = "TAG", help = "Collect URLs for jobs reporting this job tag (default = collect all gstlal_inspiral URLs).")

	options, ignored = parser.parse_args()

	return options


#
# =============================================================================
#
#                               Internal Library
#
# =============================================================================
#


class Collector(servicediscovery.Listener):
	@staticmethod
	def is_service_instance(sname, stype):
		return stype == "_http._tcp" and sname.startswith("gstlal_inspiral ")

	def __init__(self, mainloop, job_tag = None, dump_period = 180.):
		self.job_tag = job_tag
		self.dump_period = dump_period
		self.urls = {}
		self.lock = threading.Lock()
		# FIXME:  use glib's mainloop machinery instead, implement
		# this as a timeout or whatever it's called
		logging.info("starting wget loop thread thread")
		self.wget_thread = threading.Thread(target = self.wget_loop, args = (mainloop,))
		self.wget_thread.start()

	def add_service(self, sname, stype, sdomain, host, port, properties):
		if not self.is_service_instance(sname, stype):
			return
		url = "http://%s:%s/" % (host, port)
		logging.info("found '%s' server at %s for job tag '%s'" % (sname, url, properties.get("job_tag")))
		if self.job_tag is not None and properties.get("job_tag") != self.job_tag:
			logging.info("server has wrong or missing job tab, discarding")
			return
		if not properties.get("GSTLAL_LL_JOB"):
			logging.info("server has no GSTLAL_LL_JOB value, discarding")
			return
		# watch for security problems:  don't let url or job ID
		# terminate the wget shell command in mid-string
		if ";" in url or ";" in properties["GSTLAL_LL_JOB"]:
			logging.warn("invalid URL and/or job ID")
			return
		logging.info("recording server at %s for GSTLAL_LL_JOB='%s'" % (url, properties["GSTLAL_LL_JOB"]))
		with self.lock:
			self.urls[properties["GSTLAL_LL_JOB"]] = url

	def wget_loop(self, mainloop):
		try:
			while self.dump_period:
				logging.info("sleeping")
				time.sleep(self.dump_period)
				with self.lock:
					for job, url in sorted(self.urls.items()):
						assert job
						cmd = "wget -nv -nH -P %s -r %s" % (job, url)
						logging.info(cmd)
						subprocess.call(cmd, shell = True)
		except:
			mainloop.quit()
			raise

	def quit(self):
		logging.info("waiting for wget loop to finish ...")
		self.dump_period = 0	# signal exit
		self.wget_thread.join()


#
# =============================================================================
#
#                                     Main
#
# =============================================================================
#


options = parse_command_line()


logging.basicConfig(level = logging.INFO, format = "%(asctime)s %(levelname)s:%(processName)s(%(process)d):%(funcName)s: %(message)s")


mainloop = GLib.MainLoop()

collector = Collector(mainloop, job_tag = options.job_tag, dump_period = options.dump_period)
browser = servicediscovery.ServiceBrowser(collector)

try:
	mainloop.run()
except:
	collector.quit()
	raise


#
# always end on an error so that condor won't think we're done and will
# restart us
#


sys.exit(1)
