#!/usr/bin/env python

# Copyright (C) 2019  Patrick Godwin
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.	See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

__usage__ = "gstlal_ll_inspiral_event_uploader [--options]"
__description__ = "an executable to aggregate and upload GraceDB events from gstlal_inspiral jobs"
__author__ = "Patrick Godwin (patrick.godwin@ligo.org)"

#-------------------------------------------------
#				   Preamble
#-------------------------------------------------

from collections import deque, OrderedDict
import httplib
from itertools import chain
import gzip
import json
import logging
from optparse import OptionParser
import StringIO
import sys
import time

import numpy

from ligo.segments import segment
from ligo.gracedb.rest import GraceDb, HTTPError
from ligo.gracedb.rest import DEFAULT_SERVICE_URL as DEFAULT_GRACEDB_URL
from ligo.scald import utils

from lal import LIGOTimeGPS

from gstlal import events
from gstlal import inspiral

#-------------------------------------------------
#				   Functions
#-------------------------------------------------

def parse_command_line():

	parser = OptionParser(usage=__usage__, description=__description__)
	parser.add_option("-v", "--verbose", default=False, action="store_true", help = "Be verbose.")
	parser.add_option("--rootdir", metavar = "path", default = ".", help = "Sets the root directory where logs and metadata are stored.")
	parser.add_option("--num-jobs", type = int, default = 10, help="number of jobs to listen to")
	parser.add_option("--tag", metavar = "string", default = "test", help = "Sets the name of the tag used. Default = 'test'")
	parser.add_option("--max-event-time", type = "int", default = 7200, help = "Maximum time to keep around an event. Default = 2 hours.")
	parser.add_option("--common-ratio-time", type = "int", default = 4, help = "Common ratio time T for sending out subsequent events for the same event window. First event gets sent T seconds later, second event gets sent T^2 seconds later, etc. Default = 4.")
	parser.add_option("--far-threshold", type = "float", default = 3.84e-07, help = "FAR threshold considered for an event to be public, not including a trials factor. Default = 1 / month")
	parser.add_option("--far-trials-factor", type = "int", default = 1, help = "Trials factor for number of CBC pipelines uploading events to GraceDB. Default = 1.")
	parser.add_option("--processing-cadence", type = "float", default = 0.1, help = "Rate at which the event uploader acquires and processes data. Default = 0.1 seconds.")
	parser.add_option("--request-timeout", type = "float", default = 0.2, help = "Timeout for requesting messages from a topic. Default = 0.2 seconds.")
	parser.add_option("--kafka-server", metavar = "string", help = "Sets the server url that the kafka topic is hosted on. Required.")
	parser.add_option("--input-topic", metavar = "string", help = "Sets the input kafka topic. Required.")
	parser.add_option("--gracedb-group", metavar = "name", default = "Test", help = "Gracedb group to which to upload events (default is Test).")
	parser.add_option("--gracedb-pipeline", metavar = "name", default = "gstlal", help = "Name of pipeline to provide in GracedB uploads (default is gstlal).")
	parser.add_option("--gracedb-search", metavar = "name", default = "LowMass", help = "Name of search to provide in GracedB uploads (default is LowMass).")
	parser.add_option("--gracedb-service-url", metavar = "url", default = DEFAULT_GRACEDB_URL, help = "Override default GracedB service url (optional, default is {}).".format(DEFAULT_GRACEDB_URL))

	options, args = parser.parse_args()

	return options, args

#-------------------------------------------------
#					Classes
#-------------------------------------------------

class EventUploader(events.EventProcessor):
	"""
	manages handling of incoming events, selecting the best and uploading to GraceDB.
	"""
	_name = 'event_uploader'

	def __init__(self, options):
		logging.info('setting up event uploader...')

		events.EventProcessor.__init__(
			self,
			process_cadence=options.processing_cadence,
			request_timeout=options.request_timeout,
			num_messages=options.num_jobs,
			kafka_server=options.kafka_server,
			input_topic=options.input_topic,
			tag=options.tag
		)

		### initialize timing options
		self.max_event_time = options.max_event_time
		self.retries = 5
		self.retry_delay = 1

		### initialize gracedb client
		if options.gracedb_service_url.startswith("file"):
			self.client = inspiral.FakeGracedbClient(options.gracedb_service_url)
		else:
			self.client = GraceDb(options.gracedb_service_url)

		### gracedb settings
		self.gracedb_group = options.gracedb_group
		self.gracedb_pipeline = options.gracedb_pipeline
		self.gracedb_search = options.gracedb_search
		self.common_ratio_time = options.common_ratio_time

		### initialize event store
		self.events = OrderedDict()

		### favored event settings
		self.public_far_threshold = options.far_threshold / options.far_trials_factor
		self.favored_event_topic = 'favored_events'
		self.p_astro_topic = 'p_astro'


	def ingest(self, message):
		"""
		parse a message containing a candidate event
		"""
		### process candidate event
		candidate = json.loads(message.value())
		candidate['time'] = LIGOTimeGPS(candidate['time'], candidate.pop('time_ns'))
		self.process_candidate(candidate)


	def process_candidate(self, candidate):
		"""
		handles the processing of a candidate, creating
		a new event if necessary
		"""
		key = self.event_window(candidate['time'])
		if key in self.events:
			logging.info('adding new candidate for event: [{:.1f}, {:.1f}]'.format(*key))
			self.events[key]['candidates'].append(candidate)
		else:
			new_event = True
			for seg, event in self.events.items():
				if segment(candidate['time'], candidate['time']) in seg:
					logging.info('adding new candidate for time window: [{:.1f}, {:.1f}]'.format(*seg))
					event['candidates'].append(candidate)
					new_event = False

			### event not found, create a new event
			if new_event:
				logging.info('found new event: [{:.1f}, {:.1f}]'.format(*key))
				self.events[key] = self.new_event()
				self.events[key]['candidates'].append(candidate)


	def event_window(self, t):
		"""
		returns the event window representing the event
		"""
		dt = 0.2
		return segment(utils.floor_div(t - dt, 0.5), utils.floor_div(t + dt, 0.5) + 0.5)


	def new_event(self):
		"""
		returns the structure that defines an event
		"""
		return {
			'num_sent': 0,
			'time_sent': None,
			'favored': None,
			'candidates': deque(maxlen = self.num_messages)
		}


	def handle(self):
		"""
		handle events stored, selecting the best candidate.
		upload if a new favored event is found
		"""
		for key, event in sorted(self.events.items(), reverse=True):
			if event['num_sent'] == 0:
				updated, event = self.process_candidates(event)
				assert updated
				logging.info(
					'uploading {} candidate with FAR = {:.3E}, '
					'SNR = {:2.1f} for event: [{:.1f}, {:.1f}]'.format(
						self.to_ordinal(1),
						event['favored']['far'],
						event['favored']['snr'],
						key[0], key[1],
					)
				)
				self.send_favored_event(event, key)
				self.send_p_astro(event, key)
				sent = self.upload_event(event)
				if sent:
					event['num_sent'] += 1

			elif event['candidates'] and utils.gps_now() >= self.next_event_upload(event):
				updated, event = self.process_candidates(event)
				if updated:
					logging.info(
						'uploading {} candidate with FAR = {:.3E}, '
						'SNR = {:2.1f} for event: [{:.1f}, {:.1f}]'.format(
							self.to_ordinal(event['num_sent'] + 1),
							event['favored']['far'],
							event['favored']['snr'],
							key[0], key[1]
						)
					)
					self.send_favored_event(event, key)
					self.send_p_astro(event, key)
					sent = self.upload_event(event)
					if sent:
						event['num_sent'] += 1

		# clean out old events
		current_time = utils.gps_now()
		for key in list(self.events.keys()):
			if current_time - key[0] >= self.max_event_time:
				logging.info('removing stale event [{:.1f}, {:.1f}]'.format(*key))
				self.events.pop(key)


	def process_candidates(self, event):
		"""
		process candidates and update the favored event
		if needed

		returns event and whether the favored event was updated
		"""
		favored = self.select_favored_event(event['candidates'])
		event['candidates'].clear()

		### no favored event yet
		if not event['favored']:
			logging.info(
				'found candidate with FAR: {:.3E}, '
				'SNR: {:2.1f}'.format(favored['far'], favored['snr'])
			)
			event['favored'] = favored
			return True, event

		### favored event is more significant
		elif favored == self.select_favored_event([event['favored'], favored]):
			logging.info(
				'found new favored candidate with FAR: {:.3E}, '
				'SNR: {:2.1f}'.format(favored['far'], favored['snr'])
			)
			event['favored'] = favored
			return True, event

		### previous favored is better
		else:
			return False, event


	def select_favored_event(self, candidates):
		"""
		select the best event out of the candidates

		selection process is as follows:
		    * FAR >  public threshold, choose lowest FAR
		    * FAR <= public threshold, choose highest SNR
		"""
		def keyfunc(candidate):
		    return (candidate['far'] <= self.public_far_threshold), candidate['snr']

		return max(candidates, key=keyfunc)


	def send_p_astro(self, event, event_window):
		"""
		send p(astro) via Kafka
		"""
		p_astro = {
			'event_window': list(event_window),
			'time': event['favored']['time'].gpsSeconds,
			'time_ns': event['favored']['time'].gpsNanoSeconds,
			'p_astro': event['favored']['p_astro']
		}
		self.producer.produce(topic=self.p_astro_topic, value=json.dumps(p_astro))
		self.producer.poll(0)


	def send_favored_event(self, event, event_window):
		"""
		send a favored event via Kafka
		"""
		favored_event = {
			'event_window': list(event_window),
			'time': event['favored']['time'].gpsSeconds,
			'time_ns': event['favored']['time'].gpsNanoSeconds,
			'snr': event['favored']['snr'],
			'far': event['favored']['far'],
			'coinc': event['favored']['coinc']
		}
		self.producer.produce(topic=self.favored_event_topic, value=json.dumps(favored_event))
		self.producer.poll(0)


	def upload_event(self, event):
		"""
		upload a new event + auxiliary files
		"""
		if not event['time_sent']:
			event['time_sent'] = utils.gps_now()
		for attempt in range(1, self.retries + 1):
			try:
				resp = self.client.createEvent(
					self.gracedb_group,
					self.gracedb_pipeline,
					'coinc.xml',
					filecontents = event['favored']['coinc'],
					search = self.gracedb_search
				)
			except HTTPError as resp:
				logging.warning(resp)
			else:
				resp_json = resp.json()
				if resp.status == httplib.CREATED:
					graceid = resp_json['graceid']
					logging.info("event assigned grace ID {}".format(graceid))
					self.upload_file(
						"GstLAL internally computed p-astro",
						"p_astro.json",
						"p_astro",
						event['favored']['p_astro'],
						graceid
					)
					try:
						resp = self.client.writeLabel(graceid, 'PASTRO_READY')
					except HTTPError as resp:
						logging.warning(resp)
					break
			logging.warning(
				"gracedb upload of {} "
				"failed on attempt {:d}/{:d}".format(filename, attempt, self.retries)
			)
			time.sleep(random.lognormal(math.log(self.retry_delay), .5))
		else:
			logging.warning("gracedb upload of {} failed".format(filename))
			return False

		# gzip and upload psd
		psd_fobj = StringIO.StringIO()
		with gzip.GzipFile(fileobj=psd_fobj, mode="wb", compresslevel=3) as f:
			f.write(event['favored']['psd'])
		self.upload_file("strain PSDs", "psd.xml.gz", "psd", psd_fobj.getvalue(), graceid)
		del psd_fobj
		return True


	def upload_file(self, message, filename, tag, contents, graceid):
		"""
		upload a file to gracedb
		"""
		logging.info("posting '{}' to gracedb ID {}".format(filename, graceid))
		for attempt in range(1, self.retries + 1):
			try:
				resp = self.client.writeLog(
					graceid,
					message,
					filename = filename,
					filecontents = contents,
					tagname = tag
				)
			except HTTPError as resp:
				logging.warning(resp)
			else:
				if resp.status == httplib.CREATED:
					break
			logging.info(
				"gracedb upload of {} for ID {} "
				"failed on attempt {:d}/{:d}".format(filename, graceid, attempt, self.retries)
			)
			time.sleep(random.lognormal(math.log(self.retry_delay), .5))
		else:
			logging.warning("gracedb upload of {} for ID {} failed".format(filename, graceid))
			return False


	def next_event_upload(self, event):
		"""
		check whether enough time has elapsed to send an updated event
		"""
		return event['time_sent'] + numpy.power(self.common_ratio_time, event['num_sent'])


	def finish(self):
		"""
		send remaining events before shutting down
		"""
		self.handle()


	@staticmethod
	def to_ordinal(n):
		"""
		given an integer, returns the ordinal number
		representation.

		this black magic is taken from
		https://stackoverflow.com/a/20007730
		"""
		return "%d%s" % (n,"tsnrhtdd"[(n/10%10!=1)*(n%10<4)*n%10::4])


#-------------------------------------------------
#					 Main
#-------------------------------------------------

if __name__ == '__main__':
	# parse arguments
	options, args = parse_command_line()

	# set up logging
	log_level = logging.DEBUG if options.verbose else logging.INFO
	logging.basicConfig(format = '%(asctime)s | event_uploader : %(levelname)s : %(message)s')
	logging.getLogger().setLevel(log_level)

	# create event uploader instance
	event_uploader = EventUploader(options)

	# start up
	event_uploader.start()
