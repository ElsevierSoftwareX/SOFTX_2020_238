#!/usr/bin/env python
"""
DAG generator script
"""
__copyright__ = "Copyright 2010, Leo Singer"
__author__    = "Leo Singer <leo.singer@ligo.org>"



#
# Parse command line options.
#

from optparse import Option, OptionParser
import tempfile

opts, args = OptionParser(description = __doc__, option_list = [
	Option("-n", "--num-templates", type=int, default=128, metavar="INT", help="Number of templates per sub-bank"),
	Option("--flow", type="float", metavar="Hz", help="Low frequency cutoff"),
	Option("--template-bank", metavar="FILE.xml|FILE.xml.gz", help="Filename of input template bank"),
]).parse_args()



#
# Accept either the --template-bank option or a single positional argument as
# the input template bank.
#

if opts.template_bank is None and len(args) >= 1:
	opts.template_bank = args[0]
	del args[0]
if len(args) > 0:
	raise ValueError("Too many command line arguments.")
if opts.template_bank is None:
	raise ValueError("No template bank specified.")

#
# Determine temporary directory from environment.
#

tmpdir = tempfile.gettempdir()
if tmpdir is None:
	raise ValueError("No temporary directory set (did you forget to set TMPDIR in your environment?")


#
# Require certain arguments.
#

if opts.flow is None:
	raise RuntimeError, "required --flow argument not specified"



#
# Late imports.
#

from glue.ligolw import utils
from glue.ligolw import lsctables
import os.path

from pipeline import *
from pylal.progress import *

progress = ProgressBar()



#
# Open, read, and sort the original templates by mchirp.
#

head, tail = os.path.split(opts.template_bank)

progress.update(-1, 'Reading template bank')

xmldoc = utils.load_filename(opts.template_bank, gz=opts.template_bank.endswith('.gz'))
sngls = lsctables.table.get_table(xmldoc, lsctables.SnglInspiralTable.tableName)
count_sngls = len(sngls)
sorted_sngls = sorted(sngls, key=lambda x: x.mchirp)



#
# Determine the duration of the longest template.
#

# FIXME: check that the 'ttotal' column is the template duration.
bank_duration = max(sngl.ttotal for sngl in sngls)

# The time slices that are selected might result in slightly longer filters,
# so pad each job at the end with the template duration times a fudge factor.
post_padding = int(round(2 * bank_duration))



#
# Write sub-banks to disk.
#

progress.max = count_sngls
progress.update(-1, 'Writing sub-banks')

for i, start_idx in enumerate(range(0, count_sngls, opts.num_templates)):
	progress.update(start_idx)
	stop_idx = min(start_idx + opts.num_templates, count_sngls)
	sngls[:] = sorted_sngls[start_idx:stop_idx]
	path = os.path.join("tmpltbank", "%d.xml" % i)
	utils.write_filename(xmldoc, path, gz=path.endswith('.gz'))

count_sub_banks = i + 1



#
# Write the DAG.
#

progress.max = count_sub_banks
progress.update(-1, 'Generating DAG')

dag = makeDAG('lloid_paper')

# gstlal_svd_bank submit file for generating time sliced, SVD'd template banks.
gstlal_svd_bank_sub = EnvCondorJob("""gstlal_svd_bank
	--flow $(flow) --reference-psd psd.xml
	--template-bank tmpltbank/$(template_bank)
	--write-svd-bank svd/$(template_bank)
	""", outputname="log/$(Cluster).$(Process)")

compute_match_sub = EnvCondorJob("""./compute_match
	--svd-bank svd/$(template_bank)
	--impulse-responses $(tmpdir)/$(Cluster).$(Process).dat
	--flow $(flow)
	--reference-psd psd.xml
	--output $(outfilename)""",
	subfilename='compute_match', outputname="log/$(Cluster).$(Process)")

postprocess_sub = EnvCondorJob("""./postprocess -n $(count_sub_banks)""",
	subfilename='postprocess', outputname="log/$(Cluster).$(Process)")

# Assemble DAG.
postprocess_node = makeNode(dag, postprocess_sub, count_sub_banks=count_sub_banks)

for j in range(count_sub_banks):

	progress.update(j)
	template_bank = "%d.xml" % j

	# Add gstlal_svd_bank node for this bank fragment.
	gstlal_svd_bank_node = makeNode(dag, gstlal_svd_bank_sub, template_bank=template_bank, flow=opts.flow)

	# Add impulse_response node for this bank fragment.
	compute_match_node = makeNode(dag, compute_match_sub,
		template_bank=template_bank, tmpdir=tmpdir,
		flow=opts.flow, outfilename=('match/%d.out' % j),
		parents=[gstlal_svd_bank_node], children=[postprocess_node])


# Write DAG and submit files.
progress.update(-1, 'Finishing DAG')

dag.write_sub_files()
dag.write_dag()


# Print a helpful message to tell the user what to do next.
print """

Successfully generated "lloid_paper.dag".  You may now launch it with

  condor_submit_dag lloid_paper.dag
"""
