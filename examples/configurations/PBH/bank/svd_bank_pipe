#!/usr/bin/python
"""
This program makes a dag to generate svd banks
"""

__author__ = 'Chad Hanna <channa@caltech.edu>'

##############################################################################
# import standard modules and append the lalapps prefix to the python path
import sys, os, copy, math
import subprocess, socket, tempfile

##############################################################################
# import the modules we need to build the pipeline
from glue import iterutils
from glue import pipeline
from glue import lal
from glue.ligolw import lsctables
from glue import segments

def which(prog):
	which = subprocess.Popen(['which',prog], stdout=subprocess.PIPE)
	out = which.stdout.read().strip()
	if not out: 
		print >>sys.stderr, "ERROR: could not find %s in your path, have you built the proper software and source the proper env. scripts?" % (prog,prog)
		raise ValueError 
	return out

def log_path():
	host = socket.getfqdn()
	#FIXME add more hosts as you need them
	if 'caltech.edu' in host: return '/usr1/' + os.environ['USER']
	if 'phys.uwm.edu' in host: return '/localscratch/' + os.environ['USER']
	if 'aei.uni-hannover.de' in host: return '/local/user/' + os.environ['USER']
	if 'phy.syr.edu' in host: return '/usr1/' + os.environ['USER']


class bank_DAG(pipeline.CondorDAG):

	def __init__(self, name, logpath = log_path()):
		self.basename = name
		tempfile.tempdir = logpath
		tempfile.template = self.basename + '.dag.log.'
		logfile = tempfile.mktemp()
		fh = open( logfile, "w" )
		fh.close()
		pipeline.CondorDAG.__init__(self,logfile)
		self.set_dag_file(self.basename)
		self.jobsDict = {}
		self.node_id = 0
		self.output_cache = []

	def add_node(self, node):
		node.set_retry(3)
		self.node_id += 1
		node.add_macro("macroid", self.node_id)
		pipeline.CondorDAG.add_node(self, node)

	def write_cache(self):
		out = self.basename + ".cache"
		f = open(out,"w")
		for c in self.output_cache:
			f.write(str(c)+"\n")
		f.close()

class gstlal_svd_bank_job(pipeline.CondorDAGJob):
	"""
	A gstlal_svd_bank job
	"""
	def __init__(self, executable=which('gstlal_svd_bank'), tag_base='gstlal_svd_bank'):
		"""
		"""
		self.__prog__ = 'gstlal_svd_bank'
		self.__executable = executable
		self.__universe = 'vanilla'
		pipeline.CondorDAGJob.__init__(self,self.__universe,self.__executable)
		self.add_condor_cmd('getenv','True')
		self.add_condor_cmd('requirements', 'Memory > 3000') #FIXME is this enough?
		self.tag_base = tag_base
		self.add_condor_cmd('environment',"KMP_LIBRARY=serial;MKL_SERIAL=yes")
		self.set_sub_file(tag_base+'.sub')
		self.set_stdout_file('logs/'+tag_base+'-$(macroid)-$(process).out')
		self.set_stderr_file('logs/'+tag_base+'-$(macroid)-$(process).err')


class gstlal_svd_bank_node(pipeline.CondorDAGNode):
	"""
	"""
	def __init__(self, job, dag, template_bank, ifo, flow=40, reference_psd="psd.xml", tolerance=0.9999, p_node=[]):

		pipeline.CondorDAGNode.__init__(self,job)
		self.add_var_opt("flow", flow)
		self.add_var_opt("svd-tolerance", tolerance)
		self.add_var_opt("reference-psd", reference_psd)
		self.add_var_opt("template-bank", template_bank)
		svd_bank_name_path = os.path.split(template_bank)
		svd_bank_name = svd_bank_name_path[0] + "/svd_" + svd_bank_name_path[1]
		self.add_var_opt("write-svd-bank", svd_bank_name)
		dag.output_cache.append(lal.CacheEntry(ifo, "-", segments.segment(0, 999999999), "file://localhost%s" % (svd_bank_name,)))
		for p in p_node:
			self.add_parent(p)
		dag.add_node(self)


# get input arguments
ifo = sys.argv[1]
ref_psd = sys.argv[2]
input_cache = sys.argv[3]
psdname = ref_psd.split('.')[0]

try: os.mkdir("logs")
except: pass
dag = bank_DAG(psdname + "_svd_bank")

svdJob = gstlal_svd_bank_job(tag_base=psdname + "_gstlal_svd_bank")
svdNode = {}


for f in [lal.CacheEntry(line).path() for line in open(input_cache)]:
	svdNode[f] = gstlal_svd_bank_node(svdJob, dag, f, ifo, reference_psd=ref_psd)

dag.write_sub_files()
dag.write_dag()
dag.write_script()
dag.write_cache()



