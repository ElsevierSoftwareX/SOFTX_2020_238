#!/usr/bin/env python3

# Copyright (C) 2017 Sydney J. Chamberlin, Patrick Godwin, Chad Hanna, Duncan Meacher
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

"""
A program that whitens timeseries
"""


from optparse import OptionParser
import os
import sys

import gi
gi.require_version('Gst', '1.0')
from gi.repository import GObject, Gst
GObject.threads_init()
Gst.init(None)

from gstlal import aggregator
from gstlal import datasource
from gstlal import pipeparts
from gstlal import simplehandler

from gstlal.snax import multichannel_datasource
from gstlal.snax import pipeparts as snaxparts
from gstlal.snax import utils


def parse_command_line():

	parser = OptionParser(usage = '%prog [options]', description = __doc__)

	# First append the datasource common options
	multichannel_datasource.append_options(parser)
	parser.add_option("-v", "--verbose", action = "store_true", help = "Be verbose.")
	parser.add_option("--out-path", metavar = "path", default = ".", help = "Write to this path. Default = .")
	parser.add_option("--high-pass", action = "store_true", default = False, help = "Add a high-pass filter to the pipeline")
	parser.add_option("--high-pass-cutoff", type = int, default = 12, help = "Set the high-pass filter cutoff, default = 12 Hz.")
	parser.add_option("--psd-fft-length", metavar = "seconds", default = 32, type = "int", help = "The length of the FFT used to used to whiten the data (default is 32 s).")
	parser.add_option("--save-format", metavar = "format", default = "gwf", help = "Set the save format for whitened timeseries (gwf/txt). Default = gwf.")
	parser.add_option("--out-frame-type", metavar = "name", default = "WHITEN", help = "Set the frame type. Default = WHITEN.")
	parser.add_option("--frame-duration", metavar = "s", default = 16, type = "int", help = "Set the duration of the output frames.  The duration of the frame file will be multiplied by --frames-per-file.  Default: 16s")
	parser.add_option("--frames-per-file", metavar = "n", default = 4, type = "int", help = "Set the number of frames per file.  Default: 4")

	# parse the arguments and sanity check
	options, filenames = parser.parse_args()

	return options, filenames


####################
# 
#       main
#
####################   

#  
# parsing and setting up some core structures
#

options, filenames = parse_command_line()

data_source_info = multichannel_datasource.DataSourceInfo(options)
instrument = data_source_info.instrument
channels = data_source_info.channel_dict.keys()

# create output directory if it doesn't already exists
aggregator.makedir(options.out_path)

# set up logging
logger = utils.get_logger('snax_whiten', verbose=options.verbose)

#
# building the event loop and pipeline
#

logger.info("assembling pipeline...")

mainloop = GObject.MainLoop()
pipeline = Gst.Pipeline(sys.argv[0])
handler = simplehandler.Handler(mainloop, pipeline)

# generate multiple channel sources, and link up pipeline
head = snaxparts.mkmultisrc(pipeline, data_source_info, channels, verbose=options.verbose)
for channel in channels:

	# define whitening params
	samp_rate = int(data_source_info.channel_dict[channel]['fsamp'])
	max_rate = min(2048, samp_rate)

	# whiten data
	head[channel] = snaxparts.mkcondition(
		pipeline,
		head[channel],
		max_rate,
		samp_rate,
		instrument,
		channel_name=channel,
		width=32,
		psd_fft_length=options.psd_fft_length,
		high_pass=options.high_pass,
		high_pass_cutoff=options.high_pass_cutoff,
	)

# dump timeseries to disk
if options.save_format == "gwf":

	# set tags for output frames
	for channel in channels:
		ifo, channel_name = channel.split(":")
		tagstr = "units=none,channel-name=%s,instrument=%s" % (channel_name, ifo)
		head[channel] = pipeparts.mktaginject(pipeline, head[channel], tagstr)
		head[channel] = snaxparts.mktimequeue(pipeline, head[channel], max_time=0)

	# create frames
	head = pipeparts.mkframecppchannelmux(
		pipeline,
		head,
		frame_duration=options.frame_duration,
		frames_per_file=options.frames_per_file
	)

	# write the frames to disk
	head = pipeparts.mkframecppfilesink(
		pipeline,
		head,
		frame_type=options.out_frame_type,
		path=options.out_path
	)

	# Put O(100000 s) frames in each directory
	frame_dir_prefix = (options.out_path, 5)
	head.connect(
		"notify::timestamp",
		pipeparts.framecpp_filesink_ldas_path_handler,
		frame_dir_prefix
	)

elif options.save_format == "txt":
	for channel in channels:
		pipeparts.mknxydumpsink(
			pipeline,
			head[channel],
			filename=os.path.join(options.out_path, "whitenedtimeseries_%d_%s.txt" % (samp_rate, channel))
		)


# Allow Ctrl+C or sig term to gracefully shut down the program for online
# sources, otherwise it will just kill it
if data_source_info.data_source in ("lvshm", "framexmit"):# what about nds online?
	simplehandler.OneTimeSignalHandler(pipeline)

# Seek
if pipeline.set_state(Gst.State.READY) == Gst.StateChangeReturn.FAILURE:
	raise RuntimeError("pipeline failed to enter READY state")

if data_source_info.data_source not in ("lvshm", "framexmit"):# what about nds online?
	datasource.pipeline_seek_for_gps(pipeline, options.gps_start_time, options.gps_end_time)
#
# Run pipeline
#

if pipeline.set_state(Gst.State.PLAYING) == Gst.StateChangeReturn.FAILURE:
	raise RuntimeError("pipeline failed to enter PLAYING state")

logger.info("running pipeline...")

mainloop.run()

#
# Shut down pipeline
#

logger.info("shutting down pipeline...")

if pipeline.set_state(Gst.State.NULL) != Gst.StateChangeReturn.SUCCESS:
	raise RuntimeError("pipeline could not be set to NULL")

#
# close program manually if data source is live
#

if options.data_source in data_source_info.live_sources:
	sys.exit(0)
